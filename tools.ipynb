{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "cwd = os.getcwd()\n",
    "os.chdir(cwd)\n",
    "sys.path.append('tools')\n",
    "\n",
    "import chat\n",
    "import parse_data\n",
    "import sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_fname = 'stage_1-glm_4_plus-answer_generator-v1.0.0.json'\n",
    "saved_fname = 'submit-stage_1-250125.json'\n",
    "template_fname = 'submit_example.json'\n",
    "\n",
    "src_fpath = os.path.join('answer_tmp', src_fname)\n",
    "saved_fpath = os.path.join('answer', saved_fname)\n",
    "template_fpath = os.path.join('data', template_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = parse_data.read_json(src_fpath)\n",
    "answers = parse_data.read_json(template_fpath)\n",
    "\n",
    "for i in raw_data:\n",
    "    tid = i['tid']\n",
    "    try:\n",
    "        answer = i['answer_generator']['stage_1']\n",
    "        \n",
    "        for j in answers:\n",
    "            if j['tid'] == tid:\n",
    "                j['team'][0]['answer'] = answer\n",
    "    except:\n",
    "        print(tid)\n",
    "\n",
    "parse_data.write_json(answers, saved_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SIGHAN2005_PKU_CONVSEG': 'https://file.hankcs.com/hanlp/tok/sighan2005-pku-convseg_20200110_153722.zip',\n",
       " 'SIGHAN2005_MSR_CONVSEG': 'https://file.hankcs.com/hanlp/tok/convseg-msr-nocrf-noembed_20200110_153524.zip',\n",
       " 'CTB6_CONVSEG': 'https://file.hankcs.com/hanlp/tok/ctb6_convseg_nowe_nocrf_20200110_004046.zip',\n",
       " 'PKU_NAME_MERGED_SIX_MONTHS_CONVSEG': 'https://file.hankcs.com/hanlp/tok/pku98_6m_conv_ngram_20200110_134736.zip',\n",
       " 'LARGE_ALBERT_BASE': 'https://file.hankcs.com/hanlp/tok/large_corpus_cws_albert_base_20211228_160926.zip',\n",
       " 'SIGHAN2005_PKU_BERT_BASE_ZH': 'https://file.hankcs.com/hanlp/tok/sighan2005_pku_bert_base_zh_20201231_141130.zip',\n",
       " 'COARSE_ELECTRA_SMALL_ZH': 'https://file.hankcs.com/hanlp/tok/coarse_electra_small_20220616_012050.zip',\n",
       " 'FINE_ELECTRA_SMALL_ZH': 'https://file.hankcs.com/hanlp/tok/fine_electra_small_20220615_231803.zip',\n",
       " 'CTB9_TOK_ELECTRA_SMALL': 'https://file.hankcs.com/hanlp/tok/ctb9_electra_small_20220215_205427.zip',\n",
       " 'CTB9_TOK_ELECTRA_BASE': 'http://download.hanlp.com/tok/extra/ctb9_tok_electra_base_20220426_111949.zip',\n",
       " 'CTB9_TOK_ELECTRA_BASE_CRF': 'http://download.hanlp.com/tok/extra/ctb9_tok_electra_base_crf_20220426_161255.zip',\n",
       " 'MSR_TOK_ELECTRA_BASE_CRF': 'http://download.hanlp.com/tok/extra/msra_crf_electra_base_20220507_113936.zip',\n",
       " 'KYOTO_EVAHAN_TOK_LZH': 'http://download.hanlp.com/tok/extra/kyoto_evahan_tok_bert-ancient-chinese_tau_0.5_20250111_234146.zip',\n",
       " 'UD_TOK_MMINILMV2L6': 'https://file.hankcs.com/hanlp/tok/ud_tok_mMiniLMv2L6_no_space_mul_20220619_091824.zip',\n",
       " 'UD_TOK_MMINILMV2L12': 'https://file.hankcs.com/hanlp/tok/ud_tok_mMiniLMv2L12_no_space_mul_20220619_091159.zip'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'OPEN_TOK_POS_NER_SRL_DEP_SDP_CON_ELECTRA_SMALL_ZH': 'https://file.hankcs.com/hanlp/mtl/open_tok_pos_ner_srl_dep_sdp_con_electra_small_20201223_035557.zip',\n",
       " 'OPEN_TOK_POS_NER_SRL_DEP_SDP_CON_ELECTRA_BASE_ZH': 'https://file.hankcs.com/hanlp/mtl/open_tok_pos_ner_srl_dep_sdp_con_electra_base_20201223_201906.zip',\n",
       " 'CLOSE_TOK_POS_NER_SRL_DEP_SDP_CON_ELECTRA_SMALL_ZH': 'https://file.hankcs.com/hanlp/mtl/close_tok_pos_ner_srl_dep_sdp_con_electra_small_20210111_124159.zip',\n",
       " 'CLOSE_TOK_POS_NER_SRL_UDEP_SDP_CON_ELECTRA_SMALL_ZH': 'https://file.hankcs.com/hanlp/mtl/close_tok_pos_ner_srl_dep_sdp_con_electra_small_20220626_175100.zip',\n",
       " 'CLOSE_TOK_POS_NER_SRL_DEP_SDP_CON_ELECTRA_BASE_ZH': 'https://file.hankcs.com/hanlp/mtl/close_tok_pos_ner_srl_dep_sdp_con_electra_base_20210111_124519.zip',\n",
       " 'CLOSE_TOK_POS_NER_SRL_DEP_SDP_CON_ERNIE_GRAM_ZH': 'https://file.hankcs.com/hanlp/mtl/close_tok_pos_ner_srl_dep_sdp_con_ernie_gram_base_aug_20210904_145403.zip',\n",
       " 'KYOTO_EVAHAN_TOK_LEM_POS_UDEP_LZH': 'https://file.hankcs.com/hanlp/mtl/kyoto_evahan_tok_lem_pos_udep_bert-ancient-chinese_lr_1_aug_dict_20250112_154422.zip',\n",
       " 'UD_ONTONOTES_TOK_POS_LEM_FEA_NER_SRL_DEP_SDP_CON_MMINILMV2L6': 'https://file.hankcs.com/hanlp/mtl/ud_ontonotes_tok_pos_lem_fea_ner_srl_dep_sdp_con_mMiniLMv2L6_no_space_20220731_161526.zip',\n",
       " 'UD_ONTONOTES_TOK_POS_LEM_FEA_NER_SRL_DEP_SDP_CON_MMINILMV2L12': 'https://file.hankcs.com/hanlp/mtl/ud_ontonotes_tok_pos_lem_fea_ner_srl_dep_sdp_con_mMiniLMv2L12_no_space_20220807_133143.zip',\n",
       " 'UD_ONTONOTES_TOK_POS_LEM_FEA_NER_SRL_DEP_SDP_CON_XLMR_BASE': 'https://file.hankcs.com/hanlp/mtl/ud_ontonotes_tok_pos_lem_fea_ner_srl_dep_sdp_con_xlm_base_20220608_003435.zip',\n",
       " 'NPCMJ_UD_KYOTO_TOK_POS_CON_BERT_BASE_CHAR_JA': 'https://file.hankcs.com/hanlp/mtl/npcmj_ud_kyoto_tok_pos_ner_dep_con_srl_bert_base_char_ja_20210914_133742.zip',\n",
       " 'EN_TOK_LEM_POS_NER_SRL_UDEP_SDP_CON_MODERNBERT_BASE': 'https://file.hankcs.com/hanlp/mtl/en_tok_lem_pos_ner_srl_udep_sdp_con_modernbert_base_prepend_false_20241229_053838.zip',\n",
       " 'EN_TOK_LEM_POS_NER_SRL_UDEP_SDP_CON_MODERNBERT_LARGE': 'https://file.hankcs.com/hanlp/mtl/en_tok_lem_pos_ner_srl_udep_sdp_con_modernbert_large_prepend_false_20250107_181612.zip'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'MSRA_NER_BERT_BASE_ZH': 'https://file.hankcs.com/hanlp/ner/ner_bert_base_msra_20211227_114712.zip',\n",
       " 'MSRA_NER_ALBERT_BASE_ZH': 'https://file.hankcs.com/hanlp/ner/msra_ner_albert_base_20211228_173323.zip',\n",
       " 'MSRA_NER_ELECTRA_SMALL_ZH': 'https://file.hankcs.com/hanlp/ner/msra_ner_electra_small_20220215_205503.zip',\n",
       " 'CONLL03_NER_BERT_BASE_CASED_EN': 'https://file.hankcs.com/hanlp/ner/ner_conll03_bert_base_cased_en_20211227_121443.zip'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                   \r"
     ]
    }
   ],
   "source": [
    "import hanlp\n",
    "\n",
    "hanlp.pretrained.tok.ALL # 语种见名称最后一个字段或相应语料库\n",
    "hanlp.pretrained.mtl.ALL\n",
    "hanlp.pretrained.ner.ALL # 语种见名称最后一个字段或相应语料库\n",
    "\n",
    "tok = hanlp.load(hanlp.pretrained.tok.COARSE_ELECTRA_SMALL_ZH)\n",
    "# ner = hanlp.load(hanlp.pretrained.ner.MSRA_NER_ELECTRA_SMALL_ZH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['600872', '的', '全称', '、', 'A股', '简称', '、', '法人', '、', '法律顾问', '、', '会计师', '事务所', '及', '董秘', '是', '？'], ['今天', '是', '2021年12月24日', '，', '创', '近', '半年', '新高', '的', '股票', '有', '几只', '？'], ['TOUR', '他', '是否', '已经', '退市', '了', '？', '（', '是', '或者', '否', '）'], ['铜陵有色金属集团股份有限公司', '的', '法人', '代表', '是', '谁', '？'], ['海信视像科技股份有限公司', '在', '什么', '时候', '成立', '的', '，', 'XXXX-XX-XX', '？'], ['截止', '2021-06-17', '上海建工', '的', '近', '一周', '成交', '金额', '（', '万元', '）', '是', '多少', '？'], ['JD.com, Inc.', '这', '家', '公司', '在', '美股', '英文', '名称', '是', '什么', '？']]\n"
     ]
    }
   ],
   "source": [
    "tok.dict_force = {'JD.com, Inc.', '上海建工'}\n",
    "\n",
    "print(tok(['600872的全称、A股简称、法人、法律顾问、会计师事务所及董秘是？', '今天是2021年12月24日，创近半年新高的股票有几只？', 'TOUR他是否已经退市了？（是或者否）', '铜陵有色金属集团股份有限公司的法人代表是谁？', '海信视像科技股份有限公司在什么时候成立的，XXXX-XX-XX？', '截止2021-06-17上海建工的近一周成交金额（万元）是多少？', 'JD.com, Inc.这家公司在美股英文名称是什么？']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['600872', '的', '全称', '、', 'A股', '简称', '、', '法人', '、', '法律顾问', '、', '会计师', '事务所', '及', '董秘', '是', '？'], ['今天', '是', '2021年12月24日', '，', '创', '近', '半年', '新高', '的', '股票', '有', '几只', '？'], ['TOUR', '他', '是否', '已经', '退市', '了', '？', '（', '是', '或者', '否', '）'], ['铜陵有色金属集团股份有限公司', '的', '法人', '代表', '是', '谁', '？'], ['海信视像科技股份有限公司', '在', '什么', '时候', '成立', '的', '，', 'XXXX-XX-XX', '？'], ['截止', '2021-06-17', '上海', '建工', '的', '近', '一周', '成交', '金额', '（', '万元', '）', '是', '多少', '？'], ['JD.com', ',', 'Inc.', '这', '家', '公司', '在', '美股', '英文', '名称', '是', '什么', '？']]\n"
     ]
    }
   ],
   "source": [
    "print(tok(['600872的全称、A股简称、法人、法律顾问、会计师事务所及董秘是？', '今天是2021年12月24日，创近半年新高的股票有几只？', 'TOUR他是否已经退市了？（是或者否）', '铜陵有色金属集团股份有限公司的法人代表是谁？', '海信视像科技股份有限公司在什么时候成立的，XXXX-XX-XX？', '截止2021-06-17上海建工的近一周成交金额（万元）是多少？', 'JD.com, Inc.这家公司在美股英文名称是什么？'], tasks='ner*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['湘电股份', '的', '十二个月', '收盘', '最高', '价', '?']]\n"
     ]
    }
   ],
   "source": [
    "tok.dict_force = {'上海建工'}\n",
    "\n",
    "print(tok(['湘电股份的十二个月收盘最高价?']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean NER Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_path = os.path.join(cwd, 'answer_tmp' + os.sep + 'glm_4_plus-market_classifier-v1.0.0.json')\n",
    "\n",
    "questions = parse_data.read_json(question_path)\n",
    "# sort the questions by tid\n",
    "questions = sorted(questions, key=lambda x: int(x['tid'].split('-')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'ID': 16808232845300, 'InnerCode': 1000872, 'CompanyCode': 4057, 'SecuCode': '02628', 'ChiName': '中国人寿保险股份有限公司', 'ChiNameAbbr': None, 'EngName': 'China Life Insurance Company Limited', 'EngNameAbbr': 'CHINA LIFE', 'SecuAbbr': '中国人寿', 'ChiSpelling': 'ZGRS', 'SecuMarket': 72, 'SecuCategory': 3, 'ListedDate': '2003-12-18 12:00:00.000', 'ListedSector': 1, 'ListedState': 1, 'XGRQ': '2018-11-29 11:24:25.720', 'JSID': 596805865723, 'DelistingDate': None, 'ISIN': 'CNE1000002L3', 'FormerName': None, 'TradingUnit': 1000.0, 'TraCurrUnit': 1100, 'InsertTime': '2005-10-12 02:23:57.983'}], [{'ID': 694505747566, 'InnerCode': 7005304, 'SecuCode': 'LFC', 'SecuAbbr': '中国人寿', 'ChiSpelling': 'ZGRS', 'SecuCategory': 75, 'SecuMarket': 78, 'ListedSector': None, 'ListedDate': '2003-12-17 12:00:00.000', 'ListedState': 5, 'ISIN': None, 'CompanyCode': 4057, 'UpdateTime': '2022-12-18 10:06:10.113', 'JSID': 694708338161, 'DelistingDate': '2022-09-02 12:00:00.000', 'InsertTime': '2022-09-05 12:12:01.187', 'EngName': 'China Life Insurance Co. Ltd. Sponsored ADR Class H', 'ChiName': '中国人寿保险股份有限公司'}]]\n",
      "[[{'ID': 217614716484, 'InnerCode': 4874, 'CompanyCode': 3848, 'SecuCode': '601991', 'ChiName': '大唐国际发电股份有限公司', 'ChiNameAbbr': '大唐发电', 'EngName': 'Datang International Power Generation Co., Ltd.', 'EngNameAbbr': 'Datang Power', 'SecuAbbr': '大唐发电', 'ChiSpelling': 'DTFD', 'SecuMarket': 83, 'SecuCategory': 1, 'ListedDate': '2006-12-20 12:00:00.000', 'ListedSector': 1, 'ListedState': 1, 'XGRQ': '2017-03-16 04:30:01.650', 'JSID': 542953801666, 'ISIN': 'CNE000001Q02', 'ExtendedAbbr': None, 'ExtendedSpelling': None}], [{'ID': 680237631238, 'InnerCode': 7103091, 'SecuCode': 'DIPGF', 'SecuAbbr': 'Datang International Power Generation Co., Ltd. Class H', 'ChiSpelling': None, 'SecuCategory': 74, 'SecuMarket': 460, 'ListedSector': None, 'ListedDate': None, 'ListedState': 1, 'ISIN': None, 'CompanyCode': 3848, 'UpdateTime': '2022-12-18 06:27:10.133', 'JSID': 694702124529, 'DelistingDate': None, 'InsertTime': '2021-09-07 01:36:57.043', 'EngName': 'Datang International Power Generation Co., Ltd. Class H', 'ChiName': '大唐国际发电股份有限公司'}, {'ID': 680237676430, 'InnerCode': 7088264, 'SecuCode': 'DIPFF', 'SecuAbbr': 'Datang International Power Generation Co., Ltd. Class A', 'ChiSpelling': None, 'SecuCategory': 74, 'SecuMarket': 460, 'ListedSector': None, 'ListedDate': None, 'ListedState': 5, 'ISIN': None, 'CompanyCode': 3848, 'UpdateTime': '2022-12-18 06:27:10.133', 'JSID': 694702116491, 'DelistingDate': None, 'InsertTime': '2021-09-07 01:36:57.043', 'EngName': 'Datang International Power Generation Co., Ltd. Class A', 'ChiName': '大唐国际发电股份有限公司'}, {'ID': 680237677489, 'InnerCode': 7071231, 'SecuCode': 'DIPGY', 'SecuAbbr': '大唐发电', 'ChiSpelling': 'DTFD', 'SecuCategory': 75, 'SecuMarket': 460, 'ListedSector': None, 'ListedDate': '1997-03-21 12:00:00.000', 'ListedState': 5, 'ISIN': None, 'CompanyCode': 3848, 'UpdateTime': '2022-10-23 02:54:01.250', 'JSID': 694567248666, 'DelistingDate': None, 'InsertTime': '2021-09-07 01:36:57.043', 'EngName': 'Datang International Power Generation Co., Ltd. Sponsored ADR Class H', 'ChiName': '大唐国际发电股份有限公司'}]]\n",
      "[[{'ID': 16808232655600, 'InnerCode': 1000593, 'CompanyCode': 1000593, 'SecuCode': '00762', 'ChiName': '中国联合网络通信(香港)股份有限公司', 'ChiNameAbbr': None, 'EngName': 'China Unicom (Hong Kong) Limited', 'EngNameAbbr': 'CHINA UNICOM', 'SecuAbbr': '中国联通', 'ChiSpelling': 'ZGLT', 'SecuMarket': 72, 'SecuCategory': 53, 'ListedDate': '2000-06-22 12:00:00.000', 'ListedSector': 1, 'ListedState': 1, 'XGRQ': '2019-12-12 01:03:05.373', 'JSID': 629427788469, 'DelistingDate': None, 'ISIN': 'HK0000049939', 'FormerName': None, 'TradingUnit': 2000.0, 'TraCurrUnit': 1100, 'InsertTime': '2005-10-12 02:23:28.437'}], [{'ID': 680237638998, 'InnerCode': 7005264, 'SecuCode': 'CHU', 'SecuAbbr': '中国联通', 'ChiSpelling': 'ZGLT', 'SecuCategory': 75, 'SecuMarket': 78, 'ListedSector': None, 'ListedDate': '2000-06-21 12:00:00.000', 'ListedState': 5, 'ISIN': None, 'CompanyCode': 1000593, 'UpdateTime': '2022-12-30 03:39:03.297', 'JSID': 694795388512, 'DelistingDate': '2021-05-07 12:00:00.000', 'InsertTime': '2021-09-07 01:36:57.043', 'EngName': 'China Unicom (Hong Kong) Limited Sponsored ADR', 'ChiName': '中国联合网络通信（香港）股份有限公司'}]]\n",
      "[[{'ID': 16808232656300, 'InnerCode': 1000594, 'CompanyCode': 79, 'SecuCode': '00763', 'ChiName': '中兴通讯股份有限公司', 'ChiNameAbbr': None, 'EngName': 'ZTE Corporation', 'EngNameAbbr': 'ZTE', 'SecuAbbr': '中兴通讯', 'ChiSpelling': 'ZXTX', 'SecuMarket': 72, 'SecuCategory': 3, 'ListedDate': '2004-12-09 12:00:00.000', 'ListedSector': 1, 'ListedState': 1, 'XGRQ': '2018-06-19 05:01:54.580', 'JSID': 582742914581, 'DelistingDate': None, 'ISIN': 'CNE1000004Y2', 'FormerName': None, 'TradingUnit': 200.0, 'TraCurrUnit': 1100, 'InsertTime': '2005-10-12 02:23:28.513'}], [{'ID': 680237681884, 'InnerCode': 7096406, 'SecuCode': 'ZTCOF', 'SecuAbbr': 'ZTE Corporation Class H', 'ChiSpelling': None, 'SecuCategory': 74, 'SecuMarket': 460, 'ListedSector': None, 'ListedDate': None, 'ListedState': 1, 'ISIN': None, 'CompanyCode': 79, 'UpdateTime': '2022-12-18 06:27:10.133', 'JSID': 694702122090, 'DelistingDate': None, 'InsertTime': '2021-09-07 01:36:57.043', 'EngName': 'ZTE Corporation Class H', 'ChiName': '中兴通讯'}, {'ID': 680237686829, 'InnerCode': 7039860, 'SecuCode': 'ZTCOY', 'SecuAbbr': 'ZTE Corporation Unsponsored ADR Class H', 'ChiSpelling': None, 'SecuCategory': 75, 'SecuMarket': 460, 'ListedSector': None, 'ListedDate': None, 'ListedState': 5, 'ISIN': None, 'CompanyCode': 79, 'UpdateTime': '2022-12-18 06:27:10.133', 'JSID': 694702082323, 'DelistingDate': None, 'InsertTime': '2021-09-07 01:36:57.043', 'EngName': 'ZTE Corporation Unsponsored ADR Class H', 'ChiName': '中兴通讯'}]]\n"
     ]
    }
   ],
   "source": [
    "for q in questions:\n",
    "    t = q['ner']\n",
    "\n",
    "    if not t:\n",
    "        continue\n",
    "    \n",
    "    t = t['stage_1']['sql']\n",
    "\n",
    "    for k, v in t.items():\n",
    "        tmp = []\n",
    "        for j in v:\n",
    "            if j['result']:\n",
    "                tmp.append(j['result'])\n",
    "\n",
    "        if len(tmp) > 1:\n",
    "            print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "data_dir = os.path.join(cwd, \"data/table-column\")\n",
    "\n",
    "files = [i for i in os.listdir(data_dir) if \"with_table_name\" in i]\n",
    "\n",
    "column_names = set()\n",
    "\n",
    "for fname in files[:]:\n",
    "    fpath = os.path.join(data_dir, fname)\n",
    "\n",
    "    # skip line 1\n",
    "    df = pd.read_table(fpath, sep=\"|\", skiprows=[1], engine='python')\n",
    "    df = df.iloc[:, 1:-1]  # 去掉多余的边界列\n",
    "    df.columns = [col.strip() for col in df.columns]  # 去掉列名的空格\n",
    "\n",
    "    # extract column_description\n",
    "\n",
    "    cols = list(df['column_description'])\n",
    "\n",
    "    for i in range(len(cols)):\n",
    "        # sub whitespace\n",
    "        cols[i] = re.sub('\\s', '', cols[i])\n",
    "        # remove content in ()\n",
    "        cols[i] = re.sub('\\(.+\\)', '', cols[i])\n",
    "        # remove 1.1 like \n",
    "        cols[i] = re.sub('\\d\\.\\d[.)]?', '', cols[i])\n",
    "        cols[i] = re.sub('\\d[.)]?', '', cols[i])\n",
    "        # remove 一、二、 like \n",
    "        cols[i] = re.sub('^[一二三四五六七八九十]、', '', cols[i])\n",
    "        # \"#\"\n",
    "        cols[i] = re.sub('[#]+', '', cols[i])\n",
    "        # \"加:\"\n",
    "        cols[i] = re.sub('(加:)?(减:)?', '', cols[i])\n",
    "        # remove suffix digit, such as 成交量1\n",
    "        cols[i] = re.sub('\\d$', '', cols[i])\n",
    "        cols[i] = re.sub('其中：', '', cols[i])\n",
    "        \n",
    "        \n",
    "    column_names.update(set(cols))\n",
    "    \n",
    "column_names.remove('')\n",
    "\n",
    "with open('column_names.txt', 'w') as f:\n",
    "    for i in column_names:\n",
    "        tmp = f.write(i + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SIGHAN2005_PKU_CONVSEG': 'https://file.hankcs.com/hanlp/tok/sighan2005-pku-convseg_20200110_153722.zip',\n",
       " 'SIGHAN2005_MSR_CONVSEG': 'https://file.hankcs.com/hanlp/tok/convseg-msr-nocrf-noembed_20200110_153524.zip',\n",
       " 'CTB6_CONVSEG': 'https://file.hankcs.com/hanlp/tok/ctb6_convseg_nowe_nocrf_20200110_004046.zip',\n",
       " 'PKU_NAME_MERGED_SIX_MONTHS_CONVSEG': 'https://file.hankcs.com/hanlp/tok/pku98_6m_conv_ngram_20200110_134736.zip',\n",
       " 'LARGE_ALBERT_BASE': 'https://file.hankcs.com/hanlp/tok/large_corpus_cws_albert_base_20211228_160926.zip',\n",
       " 'SIGHAN2005_PKU_BERT_BASE_ZH': 'https://file.hankcs.com/hanlp/tok/sighan2005_pku_bert_base_zh_20201231_141130.zip',\n",
       " 'COARSE_ELECTRA_SMALL_ZH': 'https://file.hankcs.com/hanlp/tok/coarse_electra_small_20220616_012050.zip',\n",
       " 'FINE_ELECTRA_SMALL_ZH': 'https://file.hankcs.com/hanlp/tok/fine_electra_small_20220615_231803.zip',\n",
       " 'CTB9_TOK_ELECTRA_SMALL': 'https://file.hankcs.com/hanlp/tok/ctb9_electra_small_20220215_205427.zip',\n",
       " 'CTB9_TOK_ELECTRA_BASE': 'http://download.hanlp.com/tok/extra/ctb9_tok_electra_base_20220426_111949.zip',\n",
       " 'CTB9_TOK_ELECTRA_BASE_CRF': 'http://download.hanlp.com/tok/extra/ctb9_tok_electra_base_crf_20220426_161255.zip',\n",
       " 'MSR_TOK_ELECTRA_BASE_CRF': 'http://download.hanlp.com/tok/extra/msra_crf_electra_base_20220507_113936.zip',\n",
       " 'KYOTO_EVAHAN_TOK_LZH': 'http://download.hanlp.com/tok/extra/kyoto_evahan_tok_bert-ancient-chinese_tau_0.5_20250111_234146.zip',\n",
       " 'UD_TOK_MMINILMV2L6': 'https://file.hankcs.com/hanlp/tok/ud_tok_mMiniLMv2L6_no_space_mul_20220619_091824.zip',\n",
       " 'UD_TOK_MMINILMV2L12': 'https://file.hankcs.com/hanlp/tok/ud_tok_mMiniLMv2L12_no_space_mul_20220619_091159.zip'}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                   \r"
     ]
    }
   ],
   "source": [
    "import hanlp\n",
    "\n",
    "hanlp.pretrained.tok.ALL # 语种见名称最后一个字段或相应语料库\n",
    "\n",
    "tok = hanlp.load(hanlp.pretrained.tok.COARSE_ELECTRA_SMALL_ZH)\n",
    "\n",
    "tok.dict_force = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "历史累计分红次数\n",
      "是否分红\n",
      "历史累计分红总额\n",
      "分红股本基数\n",
      "分红对象\n",
      "变更前是否分红\n",
      "本年单位累计分红\n",
      "分红实施公告日\n",
      "本年累计分红次数\n",
      "分红意向公布日\n",
      "本年累计分红总额\n",
      "分红派息股本基准日\n",
      "变更前分红股本基数\n"
     ]
    }
   ],
   "source": [
    "for i in column_names:\n",
    "    if '分红' in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['新', '科技', '纳入', '过', '个子', '类', '概念']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def han_tok(query: str) -> str:\n",
    "\n",
    "    stop_words = {'？', '?', '有', '的', '多少', '人', '（', '）', '是', '在', '、', '分别', '了', '，'}\n",
    "\n",
    "    tok_res = tok(query)\n",
    "    res = []\n",
    "\n",
    "    for i in tok_res:\n",
    "        if i not in stop_words:\n",
    "            res.append(i)\n",
    "\n",
    "    return res\n",
    "\n",
    "han_tok('新科技纳入过多少个子类概念？')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 给 Table 添加示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "data_dir = os.path.join(cwd, \"data/table-column\")\n",
    "\n",
    "files = [i for i in os.listdir(data_dir) if \"with_table_name\" in i]\n",
    "\n",
    "ins_fpath = os.path.join(cwd, 'data/database-table/database-with_instances.json')\n",
    "\n",
    "with open(ins_fpath, 'r', encoding='utf-8') as f:\n",
    "    content = json.load(f)\n",
    "\n",
    "for fname in files[:]:\n",
    "    fpath = os.path.join(data_dir, fname)\n",
    "    table_name = fname.split('-')[0]\n",
    "\n",
    "    # skip line 1\n",
    "    df = pd.read_table(fpath, sep=\"|\", skiprows=[1], engine='python')\n",
    "    df = df.iloc[:, 1:-1]  # 去掉多余的边界列\n",
    "    df = df.fillna('')\n",
    "    df.columns = [col.strip() for col in df.columns]  # 去掉列名的空格\n",
    "    df['column_name_cleaned'] = df['column_name'].str.strip()\n",
    "\n",
    "    for i in content:\n",
    "        if i['table_name_en'] == table_name:\n",
    "            data = i\n",
    "            break\n",
    "    \n",
    "    tmp = data['sql_instances'][0]\n",
    "    tmp = {k: str(v) if v is not None else 'null' for k, v in tmp.items()}\n",
    "    df['数据示例'] = df['column_name_cleaned'].map(tmp)\n",
    "    df['数据示例'] = df['数据示例'].str[:30]\n",
    "    # 删除中间清理列 column_name_cleaned\n",
    "    df = df.drop(columns=['column_name_cleaned'])\n",
    "\n",
    "    # 转换成 Markdown 格式\n",
    "    markdown_table = df.to_markdown(index=False)\n",
    "\n",
    "    # 去除多余的空格和横线\n",
    "    markdown_table = '\\n'.join(re.sub('  ', '', line) for line in markdown_table.splitlines() if line.strip())\n",
    "    # 去除多余的 --\n",
    "    markdown_table = re.sub('\\|:-+\\|:-+\\|:-+\\|:-+\\|:-+\\|:-+\\|', '|---|---|---|---|---|---|', markdown_table)  \n",
    "\n",
    "    saved_fpath = os.path.join(data_dir, f'{table_name}-with_instance.md')  \n",
    "    with open(saved_fpath, 'w') as f:\n",
    "        t = f.write(markdown_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "fpath = '/Users/dnhb/Desktop/GitHub/zhipu-2024/final_results.json'\n",
    "\n",
    "with open(fpath, 'r') as f:\n",
    "    content = json.load(f)\n",
    "\n",
    "gold = [i for i in range(1, 101)]\n",
    "\n",
    "for i in content:\n",
    "    tmp = int(i['tid'].split('tttt----')[-1])\n",
    "    if tmp in gold:\n",
    "        gold.remove(tmp)\n",
    "\n",
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "fpath = '/Users/dnhb/Desktop/GitHub/zhipu-2024/final_results.json'\n",
    "\n",
    "with open(fpath, 'r') as f:\n",
    "    content = json.load(f)\n",
    "\n",
    "content = sorted(content, key=lambda x: int(x['tid'].split('-')[-1]))\n",
    "\n",
    "with open('/Users/dnhb/Desktop/GitHub/zhipu-2024/final_results_sorted.json', 'w', encoding='utf-8') as file:\n",
    "    # Use json.dump to write the list of dictionaries as a JSON array\n",
    "    json.dump(content, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 给 table_name 添加 dbname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "data_dir = os.path.join(cwd, \"data/table-column\")\n",
    "\n",
    "files = [i for i in os.listdir(data_dir) if \"with_instance\" in i]\n",
    "\n",
    "ins_fpath = os.path.join(cwd, 'data/database-table/database-with_instances.json')\n",
    "\n",
    "with open(ins_fpath, 'r', encoding='utf-8') as f:\n",
    "    content = json.load(f)\n",
    "\n",
    "for fname in files[:]:\n",
    "    fpath = os.path.join(data_dir, fname)\n",
    "    table_name = fname.split('-')[0]\n",
    "\n",
    "    for i in content:\n",
    "        if i['table_name_en'] == table_name:\n",
    "            db = i['database_name_en']\n",
    "\n",
    "\n",
    "    # skip line 1\n",
    "    df = pd.read_table(fpath, sep=\"|\", skiprows=[1], engine='python')\n",
    "    df = df.iloc[:, 1:-1]  # 去掉多余的边界列\n",
    "    df = df.fillna('')\n",
    "    df.columns = [col.strip() for col in df.columns]  # 去掉列名的空格\n",
    "    df['table_name'] = f'{db}.{table_name}'\n",
    "\n",
    "    # 转换成 Markdown 格式\n",
    "    markdown_table = df.to_markdown(index=False)\n",
    "\n",
    "    # 去除多余的空格和横线\n",
    "    markdown_table = '\\n'.join(re.sub('  ', '', line) for line in markdown_table.splitlines() if line.strip())\n",
    "    # 去除多余的 --\n",
    "    markdown_table = re.sub('\\|:-+\\|:-+\\|:-+\\|:-+\\|:-+\\|:-+\\|', '|---|---|---|---|---|---|', markdown_table)  \n",
    "\n",
    "    saved_fpath = os.path.join(data_dir, f'{table_name}-with_instance.md')  \n",
    "    with open(saved_fpath, 'w') as f:\n",
    "        t = f.write(markdown_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
