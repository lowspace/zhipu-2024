{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "cwd = os.getcwd()\n",
    "os.chdir(cwd)\n",
    "sys.path.append('tools')\n",
    "\n",
    "import chat\n",
    "import parse_data\n",
    "import sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\n",
    "\n",
    "version = 'v2.2.1'\n",
    "task = 'ner'\n",
    "\n",
    "prompt_dir = os.path.join(cwd, 'prompt')\n",
    "fname = f'{task}-stage_1-{version}.md'\n",
    "prompt_fpath = os.path.join(prompt_dir, fname)\n",
    "\n",
    "with open(prompt_fpath, 'r') as f:\n",
    "    prompt_template = ''.join(f.readlines())\n",
    "\n",
    "def make_prompt(conversation_turn: dict) -> str:\n",
    "\n",
    "    query = conversation_turn['team'][0]['question']\n",
    "\n",
    "    prompt = prompt_template + query\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_path = os.path.join(cwd, 'data' + os.sep + 'question.json')\n",
    "\n",
    "questions = parse_data.read_json(question_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM-4-Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'glm_4_plus'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt_tokens': 912, 'completion_tokens': 98, 'total_tokens': 1010}\n",
      "```json\n",
      "{\n",
      "    \"reasoning_process_cot\": \"根据查询内容，'600872' 是一个股票代码，指向了一个上市公司，因此应该识别为一个代码。而'全称'、'A股简称'、'法人'、'法律顾问'、'会计师事务所'和'董秘'并没有出现在查询内容中，所以无需识别它们为实体。\",\n",
      "    \"result\": [\n",
      "        {\"代码\": \"600872\"}\n",
      "    ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "query = make_prompt(questions[0])\n",
    "\n",
    "history = []\n",
    "\n",
    "start_time = time.time()\n",
    "message = chat.create_message(query, history=history, system_prompt=system_prompt, temperature=0.1, top_p=1, response_format='text')\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "usage = chat.get_token_usage(message, True)\n",
    "content = chat.get_content(message, True)\n",
    "history = chat.build_history(history, message=message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = questions[0]\n",
    "t['ner_result'] = {}\n",
    "t['ner_result']['stage_1'] = json.loads(content.strip('`json'))\n",
    "t['token_usage'] = {}\n",
    "t['token_usage']['ner-stage_1'] = usage\n",
    "t['time_usage'] = {}\n",
    "t['time_usage']['ner-stage_1'] = f\"{execution_time:.2f}s\"\n",
    "t = [t]\n",
    "\n",
    "saved_path = os.path.join(cwd, 'answer_tmp' + os.sep + f'stage_1-{model}-{task}-test-{version}.json')\n",
    "parse_data.write_json(t, saved_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [04:29<00:00,  2.67s/it]\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "\n",
    "for question in tqdm(questions[:]):\n",
    "    \n",
    "    query = make_prompt(question)\n",
    "\n",
    "    history = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    message = chat.create_message(query, history=history, system_prompt=system_prompt, temperature=0.1, top_p=1, response_format='text')\n",
    "    end_time = time.time()\n",
    "\n",
    "    execution_time = end_time - start_time\n",
    "    usage = chat.get_token_usage(message, False)\n",
    "    content = chat.get_content(message, False)\n",
    "\n",
    "    res = question\n",
    "    res['ner'] = {}\n",
    "    res['ner']['stage_1'] = json.loads(content.strip('`json'))\n",
    "    res['token_usage'] = {}\n",
    "    res['token_usage']['ner-stage_1'] = usage\n",
    "    res['time_usage'] = {}\n",
    "    res['time_usage']['ner-stage_1'] = f\"{execution_time:.2f}s\"\n",
    "\n",
    "    answers.append(res)\n",
    "\n",
    "saved_path = os.path.join(cwd, 'answer_tmp' + os.sep + f'stage_1-{model}-{task}-{version}.json')\n",
    "parse_data.write_json(answers, saved_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepseek-chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'deepseek_v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek_api = 'sk-ba0f5eed3bea4fa6be16eb33b139c684'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "query = make_prompt(questions[0])\n",
    "\n",
    "client = OpenAI(api_key= deepseek_api, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "start_time = time.time()\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ],\n",
    "    stream=False,\n",
    "    top_p=0.7,\n",
    "    temperature=0.9\n",
    ")\n",
    "end_time = time.time()\n",
    "\n",
    "response = json.loads(response.to_json())\n",
    "content = response['choices'][0]['message']['content']\n",
    "\n",
    "content = content.strip('`json')\n",
    "usage = response['usage']\n",
    "execution_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = questions[0]\n",
    "t['ner_result'] = {}\n",
    "t['ner_result']['stage_1'] = json.loads(content.strip('`json'))\n",
    "t['token_usage'] = {}\n",
    "t['token_usage']['ner-stage_1'] = usage\n",
    "t['time_usage'] = {}\n",
    "t['time_usage']['ner-stage_1'] = f\"{execution_time:.2f}s\"\n",
    "t = [t]\n",
    "\n",
    "saved_path = os.path.join(cwd, 'answer_tmp' + os.sep + f'stage_1-{model}-{task}-test-{version}.json')\n",
    "parse_data.write_json(t, saved_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [05:33<00:00,  3.30s/it]\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "\n",
    "for question in tqdm(questions[:]):\n",
    "    \n",
    "    query = make_prompt(question)\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ],\n",
    "        stream=False,\n",
    "        top_p=0.7,\n",
    "        temperature=0.9\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    response = json.loads(response.to_json())\n",
    "    content = response['choices'][0]['message']['content']\n",
    "\n",
    "    content = content.strip('`json')\n",
    "    usage = response['usage']\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    res = question\n",
    "    res['ner'] = {}\n",
    "    res['ner']['stage_1'] = json.loads(content.strip('`json'))\n",
    "    res['token_usage'] = {}\n",
    "    res['token_usage']['ner-stage_1'] = usage\n",
    "    res['time_usage'] = {}\n",
    "    res['time_usage']['ner-stage_1'] = f\"{execution_time:.2f}s\"\n",
    "\n",
    "    answers.append(res)\n",
    "\n",
    "saved_path = os.path.join(cwd, 'answer_tmp' + os.sep + f'stage_1-{model}-{task}-{version}.json')\n",
    "parse_data.write_json(answers, saved_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Results\n",
    "\n",
    "Compare the stage 1 results => find the differences => get the correct answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: tttt----27\n",
      "deepseek_v3: []\n",
      "glm_4_plus : [{\"上市公司名称\": \"RXW\"}]\n",
      "\n",
      "\n",
      "Question ID: tttt----31\n",
      "deepseek_v3: [{\"行业名称\": \"证券公司\"}]\n",
      "glm_4_plus : []\n",
      "\n",
      "\n",
      "Question ID: tttt----43\n",
      "deepseek_v3: [{\"代码\": \"TOUR\"}]\n",
      "glm_4_plus : [{\"上市公司名称\": \"TOUR\"}]\n",
      "\n",
      "\n",
      "Question ID: tttt----47\n",
      "deepseek_v3: []\n",
      "glm_4_plus : [{\"基金公司名称\": \"中证指数有限公司\"}]\n",
      "\n",
      "\n",
      "Question ID: tttt----91\n",
      "deepseek_v3: [{\"上市公司名称\": \"中文名称缩写\"}, {\"代码\": \"证券代码\"}]\n",
      "glm_4_plus : []\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Path to the folder containing model answer files\n",
    "dir_path = os.path.join(cwd, 'answer_tmp')\n",
    "\n",
    "# List of model names\n",
    "models = ['deepseek_v3', 'glm_4_plus']\n",
    "\n",
    "# Create a dictionary of file paths for each model's JSON file\n",
    "model_files = {model: os.path.join(dir_path, f\"stage_1-{model}-{task}-{version}.json\") for model in models}\n",
    "\n",
    "# Dictionary to store the data of each model\n",
    "model_data = {}\n",
    "\n",
    "# Read the JSON data for each model\n",
    "for model, file_path in model_files.items():\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        model_data[model] = json.load(f)\n",
    "\n",
    "# Dictionary to store the data_source for each question id across different models\n",
    "data_sources = {}\n",
    "\n",
    "# Traverse through each model's data to extract the data_source for each question id\n",
    "for model in models:\n",
    "    for entry in model_data[model]:\n",
    "        data_sources.setdefault(entry['tid'].replace(' ', ''), {}).update({model: entry['ner']['stage_1']['result']})\n",
    "            \n",
    "\n",
    "# Compare the data_source for each question id across models\n",
    "for question_id, sources in data_sources.items():\n",
    "    # Check if the data_source is consistent across models\n",
    "    # Convert each model's data_source to a JSON string (to handle the dictionary comparison)\n",
    "    serialized_sources = {model: json.dumps(ds, sort_keys=True, ensure_ascii=False) for model, ds in sources.items()}\n",
    "    \n",
    "    # If there are any differences in data_source, output the details\n",
    "    if len(set(serialized_sources.values())) > 1:\n",
    "        print(f\"Question ID: {question_id}\")\n",
    "        \n",
    "        # Calculate the maximum length of model names to align the output\n",
    "        max_model_length = max(len(model) for model in models)\n",
    "        \n",
    "        # Print the data_source for each model, with aligned output\n",
    "        for model in models:\n",
    "            # Left-align model names with the calculated maximum length\n",
    "            print(f\"{model.ljust(max_model_length)}: {serialized_sources.get(model, 'No data available')}\")\n",
    "        \n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经验证，glm-4-plus 的正确率目前是 100%。\n",
    "但这里存在一些考虑：\n",
    "1. 没有行业信息，行业也是需要进行定位的。\n",
    "2. 可能 deepseek-v3 和 glm-4-plus 一起错了。\n",
    "\n",
    "----\n",
    "v2.0.0\n",
    "\n",
    "经验证，glm-4-plus 的正确率是领先的，bad cases：\n",
    "\n",
    "- \"tttt----4\": \"互联网金融属于科技概念的什么分支？这个概念的英文名称是什么？\" => Ignore\n",
    "- \"tttt----72\": \"2020-07-02风电零部件行业的总市值是多少(元)？\" => add shot\n",
    "- \"tttt----35\": \"北京国枫律师事务所2020年见证多少家公司的年度股东大会？\" => glm always didn't work\n",
    "----\n",
    "v2.2.0\n",
    "\n",
    "100%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain SQL Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_dir = os.path.join(cwd, 'answer_tmp')\n",
    "fname = 'stage_1-glm_4_plus-ner.json'\n",
    "fpath = os.path.join(answer_dir, fname)\n",
    "\n",
    "data = parse_data.read_json(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(data[:]):\n",
    "    i['ner']['stage_1'] = sql.process_ner_res(i['ner']['stage_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_fpath = os.path.join(answer_dir, 'stage_1-glm_4_plus-ner-sql.json')\n",
    "parse_data.write_json(data, target_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Results\n",
    "\n",
    "Bad cases:\n",
    "\n",
    "- ~~`{ \"id\": \"tttt----43----26-1-1\", \"question\": \"TOUR他是否已经退市了？（是或者否）\" }` => \"TOUR\" => `SecuCode` in `US_SecuMain` is a name rather a numeric code~~\n",
    "- `{'id': 'tttt----39----22-2-1', 'question': 'JD.com, Inc.这家公司在美股英文名称是什么？'}`=> \"JD.com, Inc.\" => employee `LIKE` to handle this, while `LIKE` may result in multiple results, which is very bad.\n",
    "- `{'id': 'tttt----62----35-1-1', 'question': '博时基金公司成立于（XXXX年XX月XX日）？'}` => \"博时基金公司\"\n",
    "- `{'id': 'tttt----74----18-2-1', 'question': '天弘增利短债C的基金管理人是谁？'}` => \"天弘增利短债C\" => CAN'T FOUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_dir = os.path.join(cwd, 'answer_tmp')\n",
    "fname = 'stage_1-glm_4_plus-ner-sql.json'\n",
    "fpath = os.path.join(answer_dir, fname)\n",
    "\n",
    "data = parse_data.read_json(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data[:]:  # Iterate through each element in the data list\n",
    "    ner = i['ner']['stage_1']  # Extract the 'stage_1' data from the 'ner' key\n",
    "    ner_result = i['ner']['stage_1']['result']  # Extract the 'result' from 'stage_1'\n",
    "\n",
    "    # Check if all `result` fields in the `sql` data are empty\n",
    "    all_results_empty = True  # Assume initially that all `result` fields are empty\n",
    "\n",
    "    # Iterate through the `sql` dictionary in the `ner` object\n",
    "    for key, queries in ner.get('sql', {}).items():\n",
    "        for query_info in queries:  # Iterate through each query info in the list\n",
    "            if query_info.get('result'):  # Check if the `result` field is not empty\n",
    "                all_results_empty = False\n",
    "                break  # Exit the loop immediately if a non-empty `result` is found\n",
    "        if not all_results_empty:\n",
    "            break  # Exit the outer loop if a non-empty `result` is found\n",
    "\n",
    "    # If all `result` fields are empty and `ner_result` is not empty\n",
    "    if all_results_empty and ner_result:\n",
    "        print(i['team'][0])  # Print the first element of the 'team' list\n",
    "        print(ner)  # Print the 'ner' object\n",
    "        print()  # Print an empty line for separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# company code 都相同\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://comm.chatglm.cn/finglm2/api/query\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer 21e162cdd305453dac64e7186ed3145f\"\n",
    "}\n",
    "\n",
    "data = {\n",
    "  \"sql\": \"\"\"SELECT *\n",
    "FROM ConstantDB.US_SecuMain\n",
    "WHERE \n",
    "    SecuCode LIKE '%JD.com, Inc.%' OR\n",
    "    SecuAbbr LIKE '%JD.com, Inc.%' OR\n",
    "    ChiSpelling LIKE '%JD.com, Inc.%' OR\n",
    "    EngName LIKE '%JD.com, Inc.%' OR\n",
    "    ChiName LIKE '%JD.com, Inc.%';\"\"\",\n",
    "  \"limit\": 1000\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://comm.chatglm.cn/finglm2/api/query\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer 21e162cdd305453dac64e7186ed3145f\"\n",
    "}\n",
    "\n",
    "data = {\n",
    "  \"sql\": \"\"\"SELECT *\n",
    "FROM InstitutionDB.LC_InstiArchive\n",
    "WHERE \n",
    "    ChiName LIKE '%博时基金%' OR\n",
    "    AbbrChiName LIKE '%博时基金%' OR\n",
    "    NameChiSpelling LIKE '%博时基金%' OR\n",
    "    EngName LIKE '%博时基金%' OR\n",
    "    AbbrEngName LIKE '%博时基金%';\"\"\",\n",
    "  \"limit\": 1000\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://comm.chatglm.cn/finglm2/api/query\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer 21e162cdd305453dac64e7186ed3145f\"\n",
    "}\n",
    "data = {\n",
    "  \"sql\": \"SELECT * FROM ConstantDB.SecuMain WHERE ChiName LIKE '%增利%'\",\n",
    "  \"limit\": 1\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_dir = os.path.join(cwd, 'answer_tmp')\n",
    "fname = 'stage_1-glm_4_plus-ner-sql.json'\n",
    "fpath = os.path.join(answer_dir, fname)\n",
    "\n",
    "data = parse_data.read_json(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data[:]:\n",
    "\n",
    "    if not i['ner']['stage_1']['result']:\n",
    "        print(i['team'][0])\n",
    "        continue\n",
    "\n",
    "    tmp = [j for j in list(i['ner']['stage_1']['sql'].values())][0]\n",
    "\n",
    "    all_empty = True\n",
    "    for j in tmp:\n",
    "        if j['result']:\n",
    "            all_empty = False\n",
    "    \n",
    "    if all_empty:\n",
    "        print(i['team'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
