{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "cwd = os.getcwd()\n",
    "os.chdir(cwd)\n",
    "sys.path.append('tools')\n",
    "\n",
    "import chat\n",
    "import parse_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\n",
    "\n",
    "def make_prompt(conversation_turn: dict) -> str:\n",
    "    prompt = \"\"\"## **Role**\n",
    "\n",
    "你是一个专精于金融领域的命名实体识别（NER，Named Entity Recognition）任务的模型。\n",
    "\n",
    "## **Task Description**\n",
    "\n",
    "对 `Current Query` 里的内容进行命名实体识别。需要识别的实体为四类：\n",
    "\n",
    "- 上市公司名称\n",
    "- 代码\n",
    "- 基金名称\n",
    "- 基金公司名称\n",
    "\n",
    "除此之外的实体不需要识别。\n",
    "\n",
    "### **Output Format**\n",
    "\n",
    "使用 JSON 进行输出。\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"reasoning_process_cot\": use CoT to step-by-step reason the NER results,\n",
    "    \"result\": [\n",
    "    {\"{entity_type}\": \"{entity}\"},\n",
    "    ...\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "## **Shots**\n",
    "\n",
    "**Shot 1**\n",
    "\n",
    "Current Query: 唐山港集团股份有限公司是什么时间上市的（回答XXXX-XX-XX）\n",
    "Output       : ```json\n",
    "[{\"上市公司名称\": \"唐山港集团股份有限公司\"}]\n",
    "```\n",
    "\n",
    "**Shot 2**\n",
    "\n",
    "Current Query: JD的职工总数有多少人？\n",
    "Output       : ```json\n",
    "[{\"上市公司名称\": \"JD\"}]\n",
    "```\n",
    "\n",
    "**Shot 3**\n",
    "\n",
    "Current Query: 600872的全称、A股简称、法人、法律顾问、会计师事务所及董秘是？\n",
    "Output       : ```json\n",
    "{\n",
    "    \"reasoning_process_cot\": \"根据查询内容，'600872' 是一个股票代码，指向了一个上市公司，因此应该识别为一个代码。而'法人'、'法律顾问'、'会计师事务所'和'董秘'并没有出现在查询内容中，所以无需识别它们为实体。\",\n",
    "    \"result\": [\n",
    "        {\"代码\": \"600872\"},\n",
    "    ]\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "**Shot 4**\n",
    "\n",
    "Current Query: 华夏鼎康债券A在2019年的分红次数是多少？每次分红的派现比例是多少？\n",
    "Output       : ```json\n",
    "{\n",
    "    \"reasoning_process_cot\": \"从当前查询中，可以看出涉及到一个基金名称‘华夏鼎康债券A’，以及基金的分红情况。‘华夏鼎康债券A’是一个基金名称，而查询中并未提及其他实体，如上市公司名称、股票代码等。\",\n",
    "    \"result\": [\n",
    "        {\"基金名称\": \"华夏鼎康债券A\"}\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "**Shot 5**\n",
    "\n",
    "Current Query: 易方达基金管理有限公司在19年成立了多少支基金？\n",
    "Output       : ```json\n",
    "{\n",
    "    \"reasoning_process_cot\": \"根据问题中的关键词，'易方达基金管理有限公司'是一个基金公司名称。问题询问的是该公司在2019年成立了多少支基金。因此，'易方达基金管理有限公司'是唯一的实体，属于基金公司名称。\",\n",
    "    \"result\": [\n",
    "        {\"基金公司名称\": \"易方达基金管理有限公司\"}\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "**Shot 6**\n",
    "\n",
    "Current Query: 化工纳入过多少个子类概念？\n",
    "Output       : ```json\n",
    "{\n",
    "    \"reasoning_process_cot\": \"该查询没有涉及任何具体的上市公司名称、股票代码、基金名称或基金公司名称。问题内容是关于'化工'（化学行业）及其子类概念的讨论，因此没有识别出命名实体。\",\n",
    "    \"result\": []\n",
    "}\n",
    "```\n",
    "\n",
    "## **Current Query**\n",
    "\"\"\"\n",
    "\n",
    "    first_ques = conversation_turn['team'][0]['question']\n",
    "\n",
    "    prompt = prompt + first_ques\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_path = os.path.join(cwd, 'data' + os.sep + 'question.json')\n",
    "\n",
    "questions = parse_data.read_json(question_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM-4-Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'glm_4_plus'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt_tokens': 680, 'completion_tokens': 127, 'total_tokens': 807}\n",
      "```json\n",
      "{\n",
      "    \"reasoning_process_cot\": \"根据查询内容，'600872' 是一个股票代码，指向了一个上市公司，因此应该识别为一个代码。而'全称'、'A股简称'、'法人'、'法律顾问'、'会计师事务所'及'董秘'是关于该上市公司的具体信息，但它们本身并不是需要识别的实体类型（上市公司名称、代码、基金名称、基金公司名称）。因此，只需识别'600872'为代码。\",\n",
      "    \"result\": [\n",
      "        {\"代码\": \"600872\"}\n",
      "    ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "query = make_prompt(questions[0])\n",
    "\n",
    "history = []\n",
    "\n",
    "start_time = time.time()\n",
    "message = chat.create_message(query, history=history, system_prompt=system_prompt, temperature=0.1, top_p=1, response_format='text')\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "usage = chat.get_token_usage(message, True)\n",
    "content = chat.get_content(message, True)\n",
    "history = chat.build_history(history, message=message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = questions[0]\n",
    "t['ner_result'] = {}\n",
    "t['ner_result']['stage_1'] = json.loads(content.strip('`json'))\n",
    "t['token_usage'] = {}\n",
    "t['token_usage']['ner-stage_1'] = usage\n",
    "t['time_usage'] = {}\n",
    "t['time_usage']['ner-stage_1'] = f\"{execution_time:.2f}s\"\n",
    "t = [t]\n",
    "\n",
    "saved_path = os.path.join(cwd, 'answer_tmp' + os.sep + 'stage_1-glm_4_plus-ner-test.json')\n",
    "parse_data.write_json(t, saved_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [05:15<00:00,  3.12s/it]\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "\n",
    "for question in tqdm(questions[:]):\n",
    "    \n",
    "    query = make_prompt(question)\n",
    "\n",
    "    history = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    message = chat.create_message(query, history=history, system_prompt=system_prompt, temperature=0.1, top_p=1, response_format='text')\n",
    "    end_time = time.time()\n",
    "\n",
    "    execution_time = end_time - start_time\n",
    "    usage = chat.get_token_usage(message, False)\n",
    "    content = chat.get_content(message, False)\n",
    "\n",
    "    res = question\n",
    "    res['ner_result'] = {}\n",
    "    res['ner_result']['stage_1'] = json.loads(content.strip('`json'))\n",
    "    res['token_usage'] = {}\n",
    "    res['token_usage']['ner-stage_1'] = usage\n",
    "    res['time_usage'] = {}\n",
    "    res['time_usage']['ner-stage_1'] = f\"{execution_time:.2f}s\"\n",
    "\n",
    "    answers.append(res)\n",
    "\n",
    "saved_path = os.path.join(cwd, 'answer_tmp' + os.sep + f'stage_1-{model}-ner.json')\n",
    "parse_data.write_json(answers, saved_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepseek-chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'deepseek_v3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "query = make_prompt(questions[0])\n",
    "\n",
    "client = OpenAI(api_key= deepseek_api, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "start_time = time.time()\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ],\n",
    "    stream=False,\n",
    "    top_p=0.7,\n",
    "    temperature=0.9\n",
    ")\n",
    "end_time = time.time()\n",
    "\n",
    "response = json.loads(response.to_json())\n",
    "content = response['choices'][0]['message']['content']\n",
    "\n",
    "content = content.strip('`json')\n",
    "usage = response['usage']\n",
    "execution_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = questions[0]\n",
    "t['ner_result'] = {}\n",
    "t['ner_result']['stage_1'] = json.loads(content.strip('`json'))\n",
    "t['token_usage'] = {}\n",
    "t['token_usage']['ner-stage_1'] = usage\n",
    "t['time_usage'] = {}\n",
    "t['time_usage']['ner-stage_1'] = f\"{execution_time:.2f}s\"\n",
    "t = [t]\n",
    "\n",
    "saved_path = os.path.join(cwd, 'answer_tmp' + os.sep + f'stage_1-{model}-ner-test.json')\n",
    "parse_data.write_json(t, saved_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [02:53<00:00,  1.72s/it]\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "\n",
    "for question in tqdm(questions[:]):\n",
    "    \n",
    "    query = make_prompt(question)\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ],\n",
    "        stream=False,\n",
    "        top_p=0.7,\n",
    "        temperature=0.9\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    response = json.loads(response.to_json())\n",
    "    content = response['choices'][0]['message']['content']\n",
    "\n",
    "    content = content.strip('`json')\n",
    "    usage = response['usage']\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    res = question\n",
    "    res['ner_result'] = {}\n",
    "    res['ner_result']['stage_1'] = json.loads(content.strip('`json'))\n",
    "    res['token_usage'] = {}\n",
    "    res['token_usage']['ner-stage_1'] = usage\n",
    "    res['time_usage'] = {}\n",
    "    res['time_usage']['ner-stage_1'] = f\"{execution_time:.2f}s\"\n",
    "\n",
    "    answers.append(res)\n",
    "\n",
    "saved_path = os.path.join(cwd, 'answer_tmp' + os.sep + f'stage_1-{model}-ner.json')\n",
    "parse_data.write_json(answers, saved_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Results\n",
    "\n",
    "Compare the stage 1 results => find the differences => get the correct answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question ID: tttt----11\n",
      "deepseek_v3: [{\"上市公司名称\": \"工商银行\"}, {\"代码\": \"H股代码\"}]\n",
      "glm_4_plus : [{\"上市公司名称\": \"工商银行\"}]\n",
      "\n",
      "\n",
      "Question ID: tttt----27\n",
      "deepseek_v3: []\n",
      "glm_4_plus : [{\"代码\": \"RXW\"}]\n",
      "\n",
      "\n",
      "Question ID: tttt----43\n",
      "deepseek_v3: [{\"代码\": \"TOUR\"}]\n",
      "glm_4_plus : [{\"上市公司名称\": \"TOUR\"}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Path to the folder containing model answer files\n",
    "dir_path = os.path.join(cwd, 'answer_tmp')\n",
    "\n",
    "# List of model names\n",
    "models = ['deepseek_v3', 'glm_4_plus']\n",
    "\n",
    "# Create a dictionary of file paths for each model's JSON file\n",
    "model_files = {model: os.path.join(dir_path, f\"stage_1-{model}-ner.json\") for model in models}\n",
    "\n",
    "# Dictionary to store the data of each model\n",
    "model_data = {}\n",
    "\n",
    "# Read the JSON data for each model\n",
    "for model, file_path in model_files.items():\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        model_data[model] = json.load(f)\n",
    "\n",
    "# Dictionary to store the data_source for each question id across different models\n",
    "data_sources = {}\n",
    "\n",
    "# Traverse through each model's data to extract the data_source for each question id\n",
    "for model in models:\n",
    "    for entry in model_data[model]:\n",
    "        data_sources.setdefault(entry['tid'].replace(' ', ''), {}).update({model: entry['ner_result']['stage_1']['result']})\n",
    "            \n",
    "\n",
    "# Compare the data_source for each question id across models\n",
    "for question_id, sources in data_sources.items():\n",
    "    # Check if the data_source is consistent across models\n",
    "    # Convert each model's data_source to a JSON string (to handle the dictionary comparison)\n",
    "    serialized_sources = {model: json.dumps(ds, sort_keys=True, ensure_ascii=False) for model, ds in sources.items()}\n",
    "    \n",
    "    # If there are any differences in data_source, output the details\n",
    "    if len(set(serialized_sources.values())) > 1:\n",
    "        print(f\"Question ID: {question_id}\")\n",
    "        \n",
    "        # Calculate the maximum length of model names to align the output\n",
    "        max_model_length = max(len(model) for model in models)\n",
    "        \n",
    "        # Print the data_source for each model, with aligned output\n",
    "        for model in models:\n",
    "            # Left-align model names with the calculated maximum length\n",
    "            print(f\"{model.ljust(max_model_length)}: {serialized_sources.get(model, 'No data available')}\")\n",
    "        \n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经验证，glm-4-plus 的正确率目前是 100%。\n",
    "但这里存在一些考虑：\n",
    "1. 没有行业信息，行业也是需要进行定位的。\n",
    "2. 可能 deepseek-v3 和 glm-4-plus 一起错了。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
