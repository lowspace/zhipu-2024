{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "cwd = os.getcwd()\n",
    "os.chdir(cwd)\n",
    "sys.path.append('tools')\n",
    "\n",
    "import chat\n",
    "import parse_data\n",
    "import sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_path = os.path.join(cwd, 'answer_tmp', 'stage_3-glm_4_plus-table_finder-v2.7.3.json')\n",
    "# question_path = os.path.join(cwd, 'answer_tmp', 'stage_1-glm_4_plus-ner-v2.0.0-sql-HF-Post.json')\n",
    "# question_path = os.path.join(cwd, 'answer_tmp', 'stage_1-glm_4_plus-answer_generator-test-v1.0.0.json')\n",
    "\n",
    "questions = parse_data.read_json(question_path)\n",
    "\n",
    "# sort the questions by tid\n",
    "questions = sorted(questions, key=lambda x: int(x['tid'].split('-')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Craft Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_dir = os.path.join(cwd, 'prompt')\n",
    "\n",
    "sql_1_fname = f'sql_generator-stage_1-v2.0.0.md'\n",
    "sql_2_fname = f'sql_generator-stage_2-v1.0.0.md'\n",
    "ans_fname = f'answer_generator-v1.0.0.md'\n",
    "\n",
    "with open(os.path.join(prompt_dir, sql_1_fname), 'r') as f:\n",
    "    sql_1_prompt_template = ''.join(f.readlines())\n",
    "\n",
    "with open(os.path.join(prompt_dir, sql_2_fname), 'r') as f:\n",
    "    sql_2_prompt_template = ''.join(f.readlines())\n",
    "\n",
    "with open(os.path.join(prompt_dir, ans_fname), 'r') as f:\n",
    "    ans_prompt_template = ''.join(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build sql prompt \n",
    "\n",
    "def make_prompt_sql_1(data: dict) -> str:\n",
    "    \n",
    "    prompt = sql_1_prompt_template\n",
    "\n",
    "    # Database-Table Pair(s)\n",
    "    table_finder_res = data['table_finder']['stage_1'][0]['data_source']\n",
    "    tables = [i['table'] for i in table_finder_res]\n",
    "    try:\n",
    "        del table_finder_res['question']\n",
    "    except:\n",
    "        pass\n",
    "    table_finder_res = json.dumps(table_finder_res, ensure_ascii=False, indent=2)\n",
    "    reg_p = re.compile('<Database and Table>')\n",
    "    prompt = re.sub(reg_p, table_finder_res, prompt)\n",
    "    \n",
    "    # Table Schema(s)\n",
    "    table_schema = ''\n",
    "    for table in tables:\n",
    "        table_fname = f'{table}-with_table_name.md'\n",
    "        table_dir = os.path.join(cwd, 'data' + os.sep + 'table-column')\n",
    "        table_fpath = os.path.join(table_dir, table_fname)\n",
    "        with open(table_fpath,'r') as f:\n",
    "            table_schema += ''.join(f.readlines())\n",
    "            table_schema += '\\n\\n'\n",
    "    reg_p = re.compile('<Table-Column Schema>')\n",
    "    prompt = re.sub(reg_p, table_schema, prompt)\n",
    "\n",
    "    # NER Result\n",
    "    if data['ner']['stage_1']['result']:\n",
    "        ner_res = [i for i in data['ner']['stage_1']['sql'].values() if i][0]\n",
    "        ner_res = [i['result'] for i in ner_res if i['result']][0][0]\n",
    "        ner_res = json.dumps(ner_res, ensure_ascii=False, indent=2)\n",
    "        reg_p = re.compile('<NER Result>')\n",
    "        prompt = re.sub(reg_p, ner_res, prompt)\n",
    "    else:\n",
    "        reg_p = re.compile('\\n<NER Result>\\n')\n",
    "        prompt = re.sub(reg_p, '', prompt)\n",
    "        reg_p = re.compile('\\n## NER Result\\n')\n",
    "        prompt = re.sub(reg_p, '', prompt)\n",
    "\n",
    "    # replace query\n",
    "    query = data['team'][0]['question']\n",
    "    reg_p = re.compile('<Current Query>')\n",
    "    prompt = re.sub(reg_p, query, prompt)\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def make_prompt_sql_2(data: dict, idx: int) -> str:\n",
    "    \n",
    "    prompt = sql_2_prompt_template\n",
    "\n",
    "    # Database-Table Pair(s)\n",
    "    table_finder_res = data['table_finder'][f'stage_{idx+1}'][0]['data_source']\n",
    "    tables = [i['table'] for i in table_finder_res]\n",
    "    try:\n",
    "        del table_finder_res['question']\n",
    "    except:\n",
    "        pass\n",
    "    table_finder_res = json.dumps(table_finder_res, ensure_ascii=False, indent=2)\n",
    "    reg_p = re.compile('<Database and Table>')\n",
    "    prompt = re.sub(reg_p, table_finder_res, prompt)\n",
    "    \n",
    "    # Table Schema(s)\n",
    "    table_schema = ''\n",
    "    for table in tables:\n",
    "        table_fname = f'{table}-with_table_name.md'\n",
    "        table_dir = os.path.join(cwd, 'data' + os.sep + 'table-column')\n",
    "        table_fpath = os.path.join(table_dir, table_fname)\n",
    "        with open(table_fpath,'r') as f:\n",
    "            table_schema += ''.join(f.readlines())\n",
    "            table_schema += '\\n\\n'\n",
    "    reg_p = re.compile('<Table-Column Schema>')\n",
    "    prompt = re.sub(reg_p, table_schema, prompt)\n",
    "\n",
    "    # NER Result\n",
    "    if data['ner']['stage_1']['result']:\n",
    "        ner_res = [i for i in data['ner']['stage_1']['sql'].values() if i][0]\n",
    "        ner_res = [i['result'] for i in ner_res if i['result']][0][0]\n",
    "        ner_res = json.dumps(ner_res, ensure_ascii=False, indent=2)\n",
    "        reg_p = re.compile('<NER Result>')\n",
    "        prompt = re.sub(reg_p, ner_res, prompt)\n",
    "    else:\n",
    "        reg_p = re.compile('\\n<NER Result>\\n')\n",
    "        prompt = re.sub(reg_p, '', prompt)\n",
    "        reg_p = re.compile('\\n## NER Result\\n')\n",
    "        prompt = re.sub(reg_p, '', prompt)\n",
    "\n",
    "    # Query\n",
    "    query = data['team'][idx]['question']\n",
    "    reg_p = re.compile('<Current Query>')\n",
    "    prompt = re.sub(reg_p, query, prompt)\n",
    "\n",
    "    # Answers\n",
    "    history = []\n",
    "    answers = data['answer_generator']\n",
    "    for i in range(len(answers)):\n",
    "        ans = answers[i] # {'stage_n': ans}\n",
    "        ans = list(ans.values())[0]\n",
    "        query = data['team'][i]['question']\n",
    "        history.append({'previous_query': query, \"response\": ans})\n",
    "    history = json.dumps(history, ensure_ascii=False, indent=2)\n",
    "    reg_p = re.compile('<Chat History>')\n",
    "    prompt = re.sub(reg_p, history, prompt) \n",
    "\n",
    "    return prompt\n",
    "\n",
    "def make_prompt_answer(data: dict, idx: int) -> str:\n",
    "\n",
    "    prompt = ans_prompt_template\n",
    "\n",
    "    # SQL Query\n",
    "    if f'stage_{idx+1}' in data['sql_generator']:\n",
    "        sql_query = data['sql_generator'][f'stage_{idx+1}'][0]['sql_query']\n",
    "        reg_p = re.compile('<SQL Query>')\n",
    "        prompt = re.sub(reg_p, sql_query, prompt)\n",
    "    else:\n",
    "        reg_p = re.compile('\\n<SQL Query>\\n')\n",
    "        prompt = re.sub(reg_p, '', prompt)\n",
    "        reg_p = re.compile('\\n## SQL Query\\n')\n",
    "        prompt = re.sub(reg_p, '', prompt)\n",
    "\n",
    "    # SQL Result\n",
    "    if f'stage_{idx+1}' in data['sql_generator']:\n",
    "        sql_res = str(data['sql_generator'][f'stage_{idx+1}'][0]['sql_res'])\n",
    "        reg_p = re.compile('<SQL Result>')\n",
    "        prompt = re.sub(reg_p, sql_res, prompt)\n",
    "    else:\n",
    "        reg_p = re.compile('\\n<SQL Result>\\n')\n",
    "        prompt = re.sub(reg_p, '', prompt)\n",
    "        reg_p = re.compile('\\n## SQL Result\\n')\n",
    "        prompt = re.sub(reg_p, '', prompt)\n",
    "\n",
    "    # NER Result\n",
    "    if data['ner']['stage_1']['result']:\n",
    "        ner_res = [i for i in data['ner']['stage_1']['sql'].values() if i][0]\n",
    "        ner_res = [i['result'] for i in ner_res if i['result']][0][0]\n",
    "        ner_res = json.dumps(ner_res, ensure_ascii=False, indent=2)\n",
    "        reg_p = re.compile('<NER Result>')\n",
    "        prompt = re.sub(reg_p, ner_res, prompt)\n",
    "    else:\n",
    "        reg_p = re.compile('\\n<NER Result>\\n')\n",
    "        prompt = re.sub(reg_p, '', prompt)\n",
    "        reg_p = re.compile('\\n## NER Result\\n')\n",
    "        prompt = re.sub(reg_p, '', prompt)\n",
    "\n",
    "    # replace query\n",
    "    query = data['team'][idx]['question']\n",
    "    reg_p = re.compile('<Current Query>')\n",
    "    prompt = re.sub(reg_p, query, prompt)\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# deepseek_api = 'sk-ba0f5eed3bea4fa6be16eb33b139c684'\n",
    "\n",
    "# client = OpenAI(api_key= deepseek_api, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "deepseek_api = 'db4a0fe1467d4456b3d83fe9bd413d84.shvUvvb2X9WkjRXW'\n",
    "\n",
    "client = OpenAI(api_key= deepseek_api, base_url=\"https://open.bigmodel.cn/api/paas/v4/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"6b90d15d9a234097bd56ac10c19f22fb\"\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def fetch_data(data: dict):\n",
    "    url = \"https://comm.chatglm.cn/finglm2/api/query\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'FullName': '中炬高新技术实业(集团)股份有限公司',\n",
       "  'AShareAbbreviation': '中炬高新',\n",
       "  'LegalRepresentative': '余健华',\n",
       "  'LegalConsultant': '广东卓建(中山)律师事务所',\n",
       "  'AccountingFirm': '天职国际会计师事务所（特殊普通合伙）',\n",
       "  'BoardSecretary': '郭毅航'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = {\n",
    "  \"sql\": \"SELECT sm.ChiName AS FullName, lsa.AShareAbbr AS AShareAbbreviation, lsa.LegalRepr AS LegalRepresentative, lsa.LegalConsultant AS LegalConsultant, lsa.AccountingFirm AS AccountingFirm, lsa.SecretaryBD AS BoardSecretary FROM ConstantDB.SecuMain sm JOIN AStockBasicInfoDB.LC_StockArchives lsa ON sm.CompanyCode = lsa.CompanyCode WHERE sm.SecuCode = '600872';\",\n",
    "  \"limit\": 100\n",
    "}\n",
    "\n",
    "t = fetch_data(t)\n",
    "t['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 9\n",
    "\n",
    "sql_generator_history, answer_generator_history = [], []\n",
    "\n",
    "data = questions[idx].copy()\n",
    "data['sql_generator'] = {}\n",
    "data['answer_generator'] = []\n",
    "\n",
    "max_retries = 5\n",
    "\n",
    "retry_delay = 1  # 重试延迟时间（秒）\n",
    "\n",
    "for i in tqdm(range(len(data['team']))):\n",
    "    # sql generator\n",
    "    retries = 0\n",
    "\n",
    "    while retries < max_retries:\n",
    "        should_retry = False  # 标志变量，标记是否需要重试\n",
    "\n",
    "        if i == 0:\n",
    "            llm_sql_query = make_prompt_sql_1(data)\n",
    "        else:\n",
    "            llm_sql_query = make_prompt_sql_2(data, i)\n",
    "\n",
    "        tmp_sql_generator_history = sql_generator_history.copy()\n",
    "        tmp_sql_generator_history.append({'role': 'user', 'content': llm_sql_query})\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # API 调用（增加重试机制）\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    # model=\"deepseek-chat\",\n",
    "                    model='glm-4-plus',\n",
    "                    messages=tmp_sql_generator_history,\n",
    "                    stream=False,\n",
    "                    top_p=0.7,\n",
    "                    temperature=0.9\n",
    "                )\n",
    "                break  # 如果成功，跳出重试循环\n",
    "            except Exception as e:\n",
    "                print(f\"API call failed (attempt {attempt + 1}/{max_retries}): {e}\")\n",
    "                if attempt == max_retries - 1:\n",
    "                    raise  # 如果达到最大重试次数，抛出异常\n",
    "                time.sleep(retry_delay)  # 等待一段时间后重试\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "\n",
    "        response = json.loads(response.to_json())\n",
    "        raw_content = response['choices'][0]['message']['content']\n",
    "\n",
    "        # 第一个 try-except：处理 JSON 解析\n",
    "        try:\n",
    "            content = json.loads(raw_content.strip('`json'))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing JSON {data['team'][i]['id']} (attempt {retries + 1}/{max_retries}): {e}\")\n",
    "            should_retry = True  # 标记需要重试\n",
    "\n",
    "        # 如果 JSON 解析成功，继续执行后续逻辑\n",
    "        if not should_retry:\n",
    "            usage = response['usage']\n",
    "            execution_time = end_time - start_time\n",
    "\n",
    "            data['sql_generator'][f'stage_{i+1}'] = [content]\n",
    "            data['token_usage'][f'sql_generator-stage_{i+1}'] = [usage]\n",
    "            data['time_usage'][f'sql_generator-stage_{i+1}'] = [f\"{execution_time:.2f}s\"]\n",
    "\n",
    "            post_data = {\n",
    "                'sql': content['sql_query'],\n",
    "                'limit': 1000\n",
    "            }\n",
    "\n",
    "            # 第二个 try-except：处理 fetch_data\n",
    "            try:\n",
    "                sql_res = fetch_data(post_data)['data']\n",
    "                data['sql_generator'][f'stage_{i+1}'][0]['sql_res'] = sql_res\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching SQL data {data['team'][i]['id']} (attempt {retries + 1}/{max_retries}): {e}\")\n",
    "                should_retry = True  # 标记需要重试\n",
    "\n",
    "        # 根据 should_retry 决定是否重试\n",
    "        if should_retry:\n",
    "            retries += 1\n",
    "            if retries == max_retries:\n",
    "                print(f\"Failed to process question {data['team'][i]['id']} after {max_retries} attempts.\")\n",
    "                data['sql_generator'][f'stage_{i+1}'][0]['sql_res'] = []  # 设置默认值\n",
    "            continue  # 跳过本次循环，进入下一次重试\n",
    "\n",
    "        # 如果成功，跳出重试循环\n",
    "        break\n",
    "\n",
    "    # 更新历史记录\n",
    "    sql_generator_history.extend([\n",
    "        {'role': 'user', 'content': llm_sql_query},\n",
    "        {'role': 'assistant', 'content': raw_content}\n",
    "    ])\n",
    "\n",
    "    # answer generator（保持不变）\n",
    "    llm_answer_query = make_prompt_answer(data, i)\n",
    "    answer_generator_history.append({'role': 'user', 'content': llm_answer_query})\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        # model=\"deepseek-chat\",\n",
    "        model='glm-4-plus',\n",
    "        messages=answer_generator_history,\n",
    "        stream=False,\n",
    "        top_p=0.7,\n",
    "        temperature=0.9\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    response = json.loads(response.to_json())\n",
    "    content = response['choices'][0]['message']['content']\n",
    "\n",
    "    data['answer_generator'].append({f'stage_{i+1}': content})\n",
    "    data['token_usage'][f'answer_generator-stage_{i+1}'] = [usage]\n",
    "    data['time_usage'][f'answer_generator-stage_{i+1}'] = [f\"{execution_time:.2f}s\"]\n",
    "\n",
    "    answer_generator_history.append({'role': 'assistant', 'content': content})\n",
    "\n",
    "    print(\"======llm_sql_query======\")\n",
    "    print(llm_sql_query)\n",
    "    print(\"======llm_sql_query======\")\n",
    "\n",
    "    print(\"======llm_answer_query======\")\n",
    "    print(llm_answer_query)\n",
    "    print(\"======llm_answer_query======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"query\": \"000958公司2021年主营业务产品有哪些？（合并报表调整后的，金额保留2位小数）\",\n",
      "  \"sql_cot_reasoning\": \"To find the main business products of company 000958 in 2021, we need to select the 'Project' column from the 'LC_MainOperIncome' table in the 'AStockFinanceDB' database. We also need to ensure that the data is from the adjusted consolidated financial statements, so we will include conditions for 'IfMerged' and 'IfAdjusted'. Additionally, we need to filter the data for the year 2021, so we will use the 'EndDate' column with the 'LIKE' operator. Finally, we will round the 'MainOperIncome' to 2 decimal places using the 'ROUND' function.\",\n",
      "  \"sql_query\": \"SELECT Project, ROUND(MainOperIncome, 2) AS MainOperIncome FROM AStockFinanceDB.LC_MainOperIncome WHERE CompanyCode = '000958' AND IfMerged = 1 AND IfAdjusted = 1 AND EndDate LIKE '2021%'\",\n",
      "  \"sql_explanation\": \"This SQL query retrieves the main business products and their corresponding income for company 000958 in 2021 from the 'LC_MainOperIncome' table. The 'IfMerged' and 'IfAdjusted' conditions ensure that the data is from the adjusted consolidated financial statements. The 'EndDate' condition filters the data for the year 2021. The 'ROUND' function is used to round the 'MainOperIncome' to 2 decimal places.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(sql_generator_history[1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Final Answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_fname = 'glm-answer_generator-0127.json'\n",
    "saved_fname = 'submit-stage_1-250127.json'\n",
    "template_fname = 'submit_example.json'\n",
    "\n",
    "src_fpath = os.path.join('answer_tmp', src_fname)\n",
    "saved_fpath = os.path.join('answer', saved_fname)\n",
    "template_fpath = os.path.join('data', template_fname)\n",
    "\n",
    "raw_data = parse_data.read_json(src_fpath)\n",
    "answers = parse_data.read_json(template_fpath)\n",
    "\n",
    "# raw_data = sorted(raw_data, key=lambda x: int(x['tid'].split('-')[-1]))\n",
    "\n",
    "# raw_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stage_1': '美亚光电在2021年的减持计划中，最大可减持股份数量与最小可减持股份数量的差距是0。',\n",
       " 'stage_2': '美亚光电在2021年的减持计划中涉及了1名股东。',\n",
       " 'stage_3': '美亚光电在2021年的减持计划中，股东张建军的最大减持比例最高，为0.007027%。'}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[1]['answer_generator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tttt----78\n",
      "tttt----84\n"
     ]
    }
   ],
   "source": [
    "for i in raw_data[:]:\n",
    "    tid = i['tid']\n",
    "    try:\n",
    "        for num in range(len(i['team'])):\n",
    "            answer = i['answer_generator'][f'stage_{num+1}']\n",
    "            \n",
    "            for j in answers:\n",
    "                if j['tid'] == tid:\n",
    "                    j['team'][num]['answer'] = answer\n",
    "    except:\n",
    "        print(tid)\n",
    "\n",
    "parse_data.write_json(answers, saved_fpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
