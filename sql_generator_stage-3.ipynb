{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "cwd = os.getcwd()\n",
    "os.chdir(cwd)\n",
    "sys.path.append('tools')\n",
    "\n",
    "import chat\n",
    "import parse_data\n",
    "import sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Craft Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\n",
    "\n",
    "prompt_dir = os.path.join(cwd, 'prompt')\n",
    "version = 'v1.1.0'\n",
    "fname = f'sql_generator-stage_1-{version}.md'\n",
    "prompt_fpath = os.path.join(prompt_dir, fname)\n",
    "\n",
    "with open(prompt_fpath, 'r') as f:\n",
    "    prompt_template = ''.join(f.readlines())\n",
    "\n",
    "def make_prompt(data: dict) -> str:\n",
    "\n",
    "    prompt = prompt_template\n",
    "\n",
    "    # \n",
    "    table_finder_res = data['table_finder']['stage_1'][0]['data_source'][0]\n",
    "    try:\n",
    "        del table_finder_res['question']\n",
    "    except:\n",
    "        pass\n",
    "    table = table_finder_res['table']\n",
    "    table_finder_res = json.dumps(table_finder_res, ensure_ascii=False, indent=2)\n",
    "    reg_p = re.compile('<Database and Table>')\n",
    "    prompt = re.sub(reg_p, table_finder_res, prompt)\n",
    "\n",
    "    # \n",
    "    table_fname = f'{table}-with_table_name.md'\n",
    "    table_dir = os.path.join(cwd, 'data' + os.sep + 'table-column')\n",
    "    table_fpath = os.path.join(table_dir, table_fname)\n",
    "    with open(table_fpath,'r') as f:\n",
    "        table_schema = ''.join(f.readlines())\n",
    "    reg_p = re.compile('<Table-Column Schema>')\n",
    "    prompt = re.sub(reg_p, table_schema, prompt)\n",
    "\n",
    "    # \n",
    "    if data['ner']['stage_1']['result']:\n",
    "        ner_res = [i for i in data['ner']['stage_1']['sql'].values() if i][0]\n",
    "        ner_res = [i['result'] for i in ner_res if i['result']][0][0]\n",
    "        ner_res = json.dumps(ner_res, ensure_ascii=False, indent=2)\n",
    "        reg_p = re.compile('<Background Knowledge>')\n",
    "        prompt = re.sub(reg_p, ner_res, prompt)\n",
    "    else:\n",
    "        reg_p = re.compile('<Background Knowledge>')\n",
    "        prompt = re.sub(reg_p, '', prompt)\n",
    "        reg_p = re.compile('## Background Knowledge')\n",
    "        prompt = re.sub(reg_p, '', prompt)\n",
    "\n",
    "    # replace query\n",
    "    query = data['team'][0]['question']\n",
    "    reg_p = re.compile('<Current Query>')\n",
    "    prompt = re.sub(reg_p, query, prompt)\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_path = os.path.join(cwd, 'answer_tmp' + os.sep + 'stage_1-glm_4_plus-table_finder-v2.6.2.json')\n",
    "\n",
    "questions = parse_data.read_json(question_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM-4-Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'glm_4_plus'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt_tokens': 3926, 'completion_tokens': 226, 'total_tokens': 4152}\n",
      "```json\n",
      "{\n",
      "    \"query\": \"今天是2021年12月24日，创近半年新高的股票有几只？\",\n",
      "    \"sql_cot_reasoning\": \"首先，我们需要确定今天的日期是2021年12月24日，因此我们需要在查询中使用这个日期。接着，我们要找到创近半年新高的股票，这意味着我们需要查看`IfHighestHPriceRMSix`字段是否为1。根据表结构，这个字段表示指定日期的最高价是否大于最近半年的最高价。最后，我们需要统计符合条件的股票数量，因此使用`COUNT`函数。综上所述，我们的查询将涉及选择`IfHighestHPriceRMSix`字段，并且过滤条件是`TradingDay`为2021年12月24日且`IfHighestHPriceRMSix`为1，最后使用`COUNT`函数统计数量。\",\n",
      "    \"sql_query\": \"SELECT COUNT(*) FROM AStockMarketQuotesDB.CS_StockPatterns WHERE TradingDay LIKE '2021-12-24%' AND IfHighestHPriceRMSix = 1\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "query = make_prompt(questions[1])\n",
    "\n",
    "history = []\n",
    "\n",
    "start_time = time.time()\n",
    "message = chat.create_message(query, history=history, system_prompt=system_prompt, temperature=0.7, top_p=0.9, response_format='text')\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "usage = chat.get_token_usage(message, True)\n",
    "content = chat.get_content(message, True)\n",
    "history = chat.build_history(history, message=message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = questions[1]\n",
    "t['sql_generator'] = {}\n",
    "t['sql_generator']['stage_1']= [json.loads(content.strip('`json'))]\n",
    "t['token_usage'] = {}\n",
    "t['token_usage']['sql_generator-stage_1'] = [usage]\n",
    "t['time_usage'] = {}\n",
    "t['time_usage']['sql_generator-stage_1'] = [f\"{execution_time:.2f}s\"]\n",
    "t = [t]\n",
    "\n",
    "saved_path = os.path.join(cwd, 'answer_tmp' + os.sep + f'stage_1-{model}-sql_generator-test-{version}.json')\n",
    "parse_data.write_json(t, saved_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/101 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/101 [01:48<12:57,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tttt----13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 58/101 [07:42<05:46,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tttt----58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 59/101 [08:04<08:32, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tttt----59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 63/101 [08:50<07:34, 11.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tttt----63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 64/101 [09:06<08:15, 13.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tttt----64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 72/101 [10:21<04:33,  9.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tttt----72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 73/101 [10:26<03:54,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tttt----74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 86/101 [12:37<02:30, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tttt----87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [15:07<00:00,  8.98s/it]\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "\n",
    "for question in tqdm(questions[:]):\n",
    "    try:\n",
    "        # the first question\n",
    "        query = make_prompt(question)\n",
    "\n",
    "        history = []\n",
    "\n",
    "        start_time = time.time()\n",
    "        message = chat.create_message(query, history=history, system_prompt=system_prompt, temperature=0.7, top_p=0.9, response_format='text')\n",
    "        end_time = time.time()\n",
    "\n",
    "        execution_time = end_time - start_time\n",
    "        usage = chat.get_token_usage(message, False)\n",
    "        content = chat.get_content(message, False)\n",
    "\n",
    "        res = question\n",
    "        res['sql_generator'] = {}\n",
    "        res['sql_generator']['stage_1']= [json.loads(content.strip('`json'))]\n",
    "        res['token_usage']['sql_generator-stage_1'] = [usage]\n",
    "        res['time_usage']['sql_generator-stage_1'] = [f\"{execution_time:.2f}s\"]\n",
    "\n",
    "        answers.append(res)\n",
    "    except:\n",
    "        print(question['tid'])\n",
    "\n",
    "saved_path = os.path.join(cwd, 'answer_tmp' + os.sep + f'stage_1-{model}-sql_generator-{version}.json')\n",
    "parse_data.write_json(answers, saved_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepseek-chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'deepseek_v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek_api = 'sk-ba0f5eed3bea4fa6be16eb33b139c684'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "query = make_prompt(questions[1])\n",
    "\n",
    "client = OpenAI(api_key= deepseek_api, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "start_time = time.time()\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ],\n",
    "    stream=False,\n",
    "    top_p=0.7,\n",
    "    temperature=0.9\n",
    ")\n",
    "end_time = time.time()\n",
    "\n",
    "response = json.loads(response.to_json())\n",
    "content = response['choices'][0]['message']['content']\n",
    "\n",
    "content = content.strip('`json')\n",
    "usage = response['usage']\n",
    "execution_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = questions[1]\n",
    "t['sql_generator'] = {}\n",
    "t['sql_generator']['stage_1']= [json.loads(content.strip('`json'))]\n",
    "t['token_usage'] = {}\n",
    "t['token_usage']['sql_generator-stage_1'] = [usage]\n",
    "t['time_usage'] = {}\n",
    "t['time_usage']['sql_generator-stage_1'] = [f\"{execution_time:.2f}s\"]\n",
    "t = [t]\n",
    "\n",
    "saved_path = os.path.join(cwd, 'answer_tmp' + os.sep + f'stage_1-{model}-sql_generator-test-{version}.json')\n",
    "parse_data.write_json(t, saved_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 30/101 [03:13<08:15,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tttt----30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 60/101 [06:20<06:23,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tttt----60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 73/101 [07:46<03:09,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tttt----74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 86/101 [09:13<01:44,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tttt----87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [11:07<00:00,  6.60s/it]\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "\n",
    "for question in tqdm(questions[:]):\n",
    "    try:\n",
    "        query = make_prompt(question)\n",
    "\n",
    "        start_time = time.time()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": query},\n",
    "            ],\n",
    "            stream=False,\n",
    "            top_p=0.7,\n",
    "            temperature=0.9\n",
    "        )\n",
    "        end_time = time.time()\n",
    "\n",
    "        response = json.loads(response.to_json())\n",
    "        content = response['choices'][0]['message']['content']\n",
    "\n",
    "        content = content.strip('`json')\n",
    "        usage = response['usage']\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        res = question\n",
    "        res['sql_generator'] = {}\n",
    "        res['sql_generator']['stage_1']= [json.loads(content.strip('`json'))]\n",
    "        res['token_usage']['sql_generator-stage_1'] = [usage]\n",
    "        res['time_usage']['sql_generator-stage_1'] = [f\"{execution_time:.2f}s\"]\n",
    "\n",
    "        answers.append(res)\n",
    "    except:\n",
    "        print(question['tid'])\n",
    "        \n",
    "saved_path = os.path.join(cwd, 'answer_tmp' + os.sep + f'stage_1-{model}-sql_generator-{version}.json')\n",
    "parse_data.write_json(answers, saved_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain SQL Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLM-4-Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'glm_4_plus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/93 [00:03<01:06,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 26/93 [00:17<00:32,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n",
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 34/93 [00:19<00:18,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 38/93 [00:21<00:18,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 44/93 [00:22<00:11,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n",
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 49/93 [00:23<00:09,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 57/93 [01:26<10:58, 18.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 504 Server Error: Gateway Time-out for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 69/93 [01:30<00:12,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 70/93 [01:30<00:09,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 76/93 [01:32<00:04,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n",
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 82/93 [01:33<00:02,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 84/93 [01:34<00:02,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 86/93 [01:34<00:01,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 90/93 [01:35<00:01,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:36<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "fname = f'stage_1-{model}-sql_generator-{version}.json'\n",
    "fpath = os.path.join(cwd, 'answer_tmp' + os.sep + fname)\n",
    "data = parse_data.read_json(fpath)\n",
    "\n",
    "for i in tqdm(data[:]):\n",
    "    tmp = sql.process_sql_generator_res(i['sql_generator']['stage_1'][0])\n",
    "\n",
    "fname = f'stage_1-{model}-sql_generator-{version}-sql.json'\n",
    "fpath = os.path.join(cwd, 'answer_tmp' + os.sep + fname)\n",
    "data = parse_data.write_json(data, fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deepseek-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'deepseek_v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 27/97 [00:06<00:15,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 35/97 [00:13<01:14,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 43/97 [00:23<00:47,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 48/97 [00:26<00:27,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 61/97 [00:37<00:34,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 62/97 [00:38<00:33,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 70/97 [00:43<00:14,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 88/97 [00:54<00:04,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 90/97 [00:55<00:03,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 94/97 [00:59<00:02,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 500 Server Error: Internal Server Error for url: https://comm.chatglm.cn/finglm2/api/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [01:01<00:00,  1.59it/s]\n"
     ]
    }
   ],
   "source": [
    "fname = f'stage_1-{model}-sql_generator-{version}.json'\n",
    "fpath = os.path.join(cwd, 'answer_tmp' + os.sep + fname)\n",
    "data = parse_data.read_json(fpath)\n",
    "\n",
    "for i in tqdm(data[:]):\n",
    "    tmp = sql.process_sql_generator_res(i['sql_generator']['stage_1'][0])\n",
    "\n",
    "fname = f'stage_1-{model}-sql_generator-{version}-sql.json'\n",
    "fpath = os.path.join(cwd, 'answer_tmp' + os.sep + fname)\n",
    "data = parse_data.write_json(data, fpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
