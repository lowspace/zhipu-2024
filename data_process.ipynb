{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "cwd = os.getcwd()\n",
    "os.chdir(cwd)\n",
    "sys.path.append('tools')\n",
    "\n",
    "import chat\n",
    "import parse_data\n",
    "import sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_api = \"f8bc1dd6592f491895617e1dfd1dc89b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table-column Table 的处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拆分数据字典中的表字段关系\n",
    "\n",
    "- Motivation: 表字段关系表太大，无法直接作为 context 喂给 llm，所以只能将需要的表字段关系提取出来后再喂给 llm。\n",
    "- Data Description: 为了降低未来的工作成本，同一个表格会生成两个文件，一个文件有 table_name 一个问题没有 table_name。文件名分别是 `{X}-with_table_name.md` 和 `{X}-without_table_name.md`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas\n",
    "\n",
    "cwd = os.getcwd()\n",
    "data_dir = os.path.join(cwd, 'data')\n",
    "target_dir = os.path.join(data_dir, \"table-column\")\n",
    "src_fpath = os.path.join(data_dir, '数据字典.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['库表关系', '表字段信息']\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set pandas options to display all rows and columns\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', None)  # Disable width limit\n",
    "pd.set_option('display.max_colwidth', None)  # Show full content in each cell\n",
    "\n",
    "# Read the entire Excel file and check sheet names\n",
    "xls = pd.ExcelFile(src_fpath)\n",
    "print(xls.sheet_names)  # Print all sheet names to check for Chinese names\n",
    "\n",
    "# Read the specific sheet (with Chinese name)\n",
    "df = pd.read_excel(src_fpath, sheet_name='表字段信息')  # Using the sheet name in Chinese\n",
    "\n",
    "# Group the DataFrame by 'table_name'\n",
    "grouped = df.groupby('table_name')\n",
    "\n",
    "# Function to convert DataFrame to Markdown table format\n",
    "def df_to_markdown_compact(dataframe, include_table_name=True):\n",
    "    \"\"\"\n",
    "    Convert a DataFrame to a compact Markdown table format.\n",
    "    :param dataframe: The DataFrame to convert\n",
    "    :param include_table_name: Boolean flag to include or exclude 'table_name' column\n",
    "    :return: Compact Markdown-formatted string\n",
    "    \"\"\"\n",
    "    # Remove nan values and replace them with empty strings\n",
    "    dataframe = dataframe.fillna('')\n",
    "\n",
    "    # Drop 'table_name' if not needed\n",
    "    if not include_table_name and 'table_name' in dataframe.columns:\n",
    "        dataframe = dataframe.drop(columns=['table_name'])\n",
    "    \n",
    "    # Convert to Markdown without index\n",
    "    return dataframe.to_markdown(index=False, tablefmt=\"github\").strip()\n",
    "\n",
    "# Process the first group only for debugging\n",
    "for table_name, group in grouped:\n",
    "    # Generate compact Markdown table\n",
    "    md_compact_with_table_name = df_to_markdown_compact(group, include_table_name=True)\n",
    "    md_compact_without_table_name = df_to_markdown_compact(group, include_table_name=False)\n",
    "    \n",
    "    # Save to Markdown files\n",
    "    with open(f\"{target_dir}/{table_name}-with_table_name.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "        t = f.write(f\"{md_compact_with_table_name}\")\n",
    "    \n",
    "    with open(f\"{target_dir}/{table_name}-without_table_name.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "        t = f.write(f\"{md_compact_without_table_name}\")\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## markdown 的格式预处理\n",
    "\n",
    "1. 移除两个及以上的空格。\n",
    "2. 改写第二行中 markdown table 的格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas\n",
    "\n",
    "cwd = os.getcwd()\n",
    "data_dir = os.path.join(cwd, 'data')\n",
    "src_dir = os.path.join(data_dir, \"table-column\")\n",
    "exclusive_fname = \"001-table.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(src_dir)\n",
    "# remove the original file\n",
    "files.remove(exclusive_fname)\n",
    "\n",
    "for fname in files[:]:\n",
    "    fpath = os.path.join(src_dir, fname)\n",
    "\n",
    "    with open(fpath, 'r') as f:\n",
    "        content = f.readlines()\n",
    "\n",
    "    new_content = []\n",
    "\n",
    "    for line in content:\n",
    "        line = line.replace('  ', '')\n",
    "        # make the format more readable\n",
    "        line = line.replace('| ||', ' | | |')\n",
    "        new_content.append(line)\n",
    "\n",
    "    new_content[1] = \"|---|---|---|---|---|\\n\"\n",
    "\n",
    "    with open(fpath, 'w') as f:\n",
    "        f.writelines(new_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重写备注\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database-Table 的处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 给每一个表增加 date_type 的属性\n",
    "\n",
    "Q：为什么需要添加 data type？\n",
    "A：将 query 和 table-filed schema 进行匹配的时候，避免 llm 因为缺乏必要的信息而将 query 的主体与不对应的 field 进行匹配。比如「小米的法人是谁？」，在 `LC_StockArchives` 中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取 database-table 的 pair\n",
    "\n",
    "- 保存为 JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "data_dir = os.path.join(cwd, 'data')\n",
    "target_dir = os.path.join(data_dir, \"database-table\")\n",
    "src_fpath = os.path.join(target_dir, 'database.json')\n",
    "\n",
    "with open(src_fpath, 'r') as f:\n",
    "    content = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:16<00:00,  4.55it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(content))):\n",
    "    query = content[i]\n",
    "\n",
    "    res = sql.get_description(sql_api, query)\n",
    "\n",
    "    content[i]['sql_description'] = res\n",
    "\n",
    "saved_fpath = os.path.join(target_dir, 'database-with_description.json')\n",
    "\n",
    "with open(saved_fpath, 'w', encoding='utf-8') as f:\n",
    "    json.dump(content, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对于每一个 table 都获取例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "cwd = os.getcwd()\n",
    "data_dir = os.path.join(cwd, 'data')\n",
    "target_dir = os.path.join(data_dir, \"database-table\")\n",
    "src_fpath = os.path.join(target_dir, 'database-with_description.json')\n",
    "\n",
    "with open(src_fpath, 'r') as f:\n",
    "    content = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:18<00:00,  4.15it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(content[:]))):\n",
    "    query = content[i]\n",
    "\n",
    "    try:\n",
    "        res = sql.get_instance(sql_api, query, 3)\n",
    "        content[i]['sql_instances'] = res\n",
    "    except:\n",
    "        print(content[i]['database_name_en'], content[i]['table_name_en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_fpath = os.path.join(target_dir, 'database-with_instances.json')\n",
    "\n",
    "with open(saved_fpath, 'w', encoding='utf-8') as f:\n",
    "    json.dump(content, f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
