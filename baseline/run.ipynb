{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0354883aa175ab3",
   "metadata": {},
   "source": [
    "## 初始化\n",
    "\n",
    "在这一步，你需要导入所有必要的库，并对项目中的部分参数进行初始化。包括填写 智谱AI API Key 以及一个队伍 Token。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b398081",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T17:51:00.577515Z",
     "start_time": "2024-12-16T17:51:00.574504Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "from zhipuai import ZhipuAI\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81583c66ce102c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Access_Token = '6b90d15d9a234097bd56ac10c19f22fb'  # Competition team Token, used to access the competition database\n",
    "# MODEL = \"glm-4-plus\"  # Default large model used; this solution uses the GLM-4-PLUS model entirely\n",
    "# client = ZhipuAI(api_key='Your ZhipuAI API_KEY')\n",
    "\n",
    "# MODEL = 'deepseek-chat'\n",
    "# deepseek_api = 'sk-ba0f5eed3bea4fa6be16eb33b139c684'\n",
    "# client = OpenAI(api_key= deepseek_api, base_url=\"https://api.deepseek.com\")\n",
    "MODEL = \"gpt-4o\"\n",
    "openai_api = \"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\"\n",
    "client = OpenAI(api_key= openai_api)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46d81442-e4dd-4630-86bc-dcdee86db003",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T17:51:00.798081Z",
     "start_time": "2024-12-16T17:51:00.597183Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess the competition questions here\n",
    "question_data_path = r'/Users/dnhb/Desktop/GitHub/zhipu-2024/data/question.json'\n",
    "df1 = pd.read_excel('/Users/dnhb/Desktop/GitHub/zhipu-2024/data/数据字典.xlsx', sheet_name='库表关系')\n",
    "df2 = pd.read_excel('/Users/dnhb/Desktop/GitHub/zhipu-2024/data/数据字典.xlsx', sheet_name='表字段信息')\n",
    "file_path = '/Users/dnhb/Desktop/GitHub/zhipu-2024/data/all_tables_schema.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c780370c7fa1cb6",
   "metadata": {},
   "source": [
    "这部分代码对数据库进读入，为预处理做准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ccab54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T17:51:00.837232Z",
     "start_time": "2024-12-16T17:51:00.806726Z"
    }
   },
   "outputs": [],
   "source": [
    "df1['库表名英文'] = df1['库名英文'] + '.' + df1['表英文']\n",
    "df1['库表名中文'] = df1['库名中文'] + '.' + df1['表中文']\n",
    "\n",
    "database_name = list(df1['库名中文'])\n",
    "table_name = list(df1['表中文'])\n",
    "table_name_en = list(df1['表英文'])\n",
    "database_table_ch = list(df1['库表名中文'])\n",
    "database_table_en = list(df1['库表名英文'])\n",
    "database_table_en_zs = {'库表名': database_table_en, '对应中文注释说明': table_name}\n",
    "database_table_map = df1.set_index('库表名中文')['库表名英文'].to_dict()\n",
    "\n",
    "database_L = []\n",
    "database_L_zh = []\n",
    "for i in table_name_en:\n",
    "    df3 = df2[df2['table_name'] == i]\n",
    "    name = df1[df1['表英文'] == i]['库表名英文'].iloc[0]\n",
    "    column_name = list(df3['column_name'])\n",
    "    column_name_zh = list(df3['column_description'])\n",
    "    column_name_2 = list(df3['注释'].dropna())\n",
    "\n",
    "    dict_1 = {'数据表名': name, '列名': column_name, '注释': column_name_2}\n",
    "    dict_2 = {'数据表名': name, '列名': column_name, '列名中文描述': column_name_zh, '注释': column_name_2}\n",
    "    database_L.append(dict_1)\n",
    "    database_L_zh.append(dict_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677cf3bd631c5651",
   "metadata": {},
   "source": [
    "## 工具函数\n",
    "\n",
    "这里提到了本项目会用到的所有工具函数，为完成任务所设置。具体功能可以查看代码中关于解释的部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2193ce99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T17:51:00.860313Z",
     "start_time": "2024-12-16T17:51:00.845378Z"
    }
   },
   "outputs": [],
   "source": [
    "# def create_chat_completion(messages, model=MODEL):\n",
    "#     \"\"\"\n",
    "#     Create a chat completion using the provided messages and model.\n",
    "    \n",
    "#     Parameters:\n",
    "#         messages (list): A list of message dictionaries to pass to the model.\n",
    "#         model (str): The model name to use.\n",
    "    \n",
    "#     Returns:\n",
    "#         response (dict): The response from the chat completion endpoint.\n",
    "#     \"\"\"\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=model,\n",
    "#         stream=False,\n",
    "#         messages=messages\n",
    "#     )\n",
    "#     return response\n",
    "\n",
    "def create_chat_completion(messages, model=MODEL):\n",
    "    \"\"\"\n",
    "    Create a chat completion using the provided messages and model.\n",
    "    \n",
    "    Parameters:\n",
    "        messages (list): A list of message dictionaries to pass to the model.\n",
    "        model (str): The model name to use.\n",
    "    \n",
    "    Returns:\n",
    "        response (dict): The response from the chat completion endpoint.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        stream=False,\n",
    "        top_p=0.7,\n",
    "        temperature=0.9\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def filter_table_comments(question, table_comments):\n",
    "    \"\"\"\n",
    "    Filter a list of table comments based on the given question. \n",
    "    Uses jieba for segmentation and removes stopwords, returning only comments \n",
    "    that contain at least one of the segmented keywords.\n",
    "    \n",
    "    Parameters:\n",
    "        question (str): The question text.\n",
    "        table_comments (list): A list of comment strings to filter.\n",
    "    \n",
    "    Returns:\n",
    "        filtered_comments (list): Filtered list of comments.\n",
    "    \"\"\"\n",
    "    stopwords = ['？', '有', '的', '多少', '人', '（', '）']\n",
    "    seg_list = list(jieba.cut(question, cut_all=False))\n",
    "    filtered_seg_list = [word for word in seg_list if word not in stopwords]\n",
    "\n",
    "    filtered_comments = []\n",
    "    for comment in table_comments:\n",
    "        if any(keyword in comment for keyword in filtered_seg_list):\n",
    "            filtered_comments.append(comment)\n",
    "    return filtered_comments\n",
    "\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "input_text = content\n",
    "\n",
    "\n",
    "def parse_table_structures(input_text):\n",
    "    \"\"\"\n",
    "    Parse the input text to extract table structures. \n",
    "    \n",
    "    The format is expected as pairs: \"table_name === table_structure\".\n",
    "    \n",
    "    Parameters:\n",
    "        input_text (str): The raw text containing table structures.\n",
    "        \n",
    "    Returns:\n",
    "        tables_dict (dict): A dictionary where keys are table names and \n",
    "                            values are the associated table structures.\n",
    "    \"\"\"\n",
    "    tables_text = input_text.split('===')[1:]\n",
    "    tables_dict = {tables_text[i]: tables_text[i + 1] for i in range(0, len(tables_text), 2)}\n",
    "    return tables_dict\n",
    "\n",
    "\n",
    "def map_chinese_to_english_tables(chinese_names, english_names):\n",
    "    \"\"\"\n",
    "    Map Chinese table names to their corresponding English table names.\n",
    "    For each Chinese name, there is a matching English name \n",
    "    (case-insensitive comparison).\n",
    "    \n",
    "    Parameters:\n",
    "        chinese_names (list): A list of Chinese table names.\n",
    "        english_names (list): A list of English table names.\n",
    "        \n",
    "    Returns:\n",
    "        name_map (dict): A dictionary mapping Chinese table names to English table names.\n",
    "    \"\"\"\n",
    "    name_map = {}\n",
    "    for cname in chinese_names:\n",
    "        # Find the corresponding English name (case-insensitive match)\n",
    "        english_match = [en for en in english_names if str(en).lower() == cname.lower()][0]\n",
    "        name_map[cname] = english_match\n",
    "    return name_map\n",
    "\n",
    "\n",
    "def find_value_in_list_of_dicts(dict_list, key_to_match, value_to_match, key_to_return):\n",
    "    \"\"\"\n",
    "    Search through a list of dictionaries and find the first dictionary where \n",
    "    the value of key_to_match equals value_to_match, then return the value \n",
    "    associated with key_to_return.\n",
    "    \n",
    "    Parameters:\n",
    "        dict_list (list): A list of dictionaries to search through.\n",
    "        key_to_match (str): The key whose value we want to match.\n",
    "        value_to_match (str): The value we are looking for.\n",
    "        key_to_return (str): The key whose value we want to return.\n",
    "        \n",
    "    Returns:\n",
    "        (str): The value associated with key_to_return in the matching dictionary, \n",
    "               or an empty string if no match is found.\n",
    "    \"\"\"\n",
    "    for dictionary in dict_list:\n",
    "        if dictionary.get(key_to_match) == value_to_match:\n",
    "            return dictionary.get(key_to_return)\n",
    "    return ''\n",
    "\n",
    "\n",
    "def get_table_schema(question=''):\n",
    "    \"\"\"\n",
    "    Retrieve table schemas along with optional filtered field comments.\n",
    "    If a question is provided, the comments will be filtered based on \n",
    "    question keywords.\n",
    "    \n",
    "    The function:\n",
    "      1. Maps Chinese table names to English table names.\n",
    "      2. For each table, retrieves its structure and finds associated comments.\n",
    "      3. If a question is provided, filter the comments based on keywords extracted from the question.\n",
    "    \n",
    "    Parameters:\n",
    "        question (str): The question text. If empty, no filtering is performed.\n",
    "        \n",
    "    Returns:\n",
    "        table_maps (list): A list of dictionaries, each containing table schema information.\n",
    "        {\n",
    "            '数据表名': EnglishTableName,\n",
    "            '数据表结构': TableStructure,\n",
    "            '字段注释': FilteredComments (optional if question is provided)\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    parsed_tables = parse_table_structures(input_text)\n",
    "\n",
    "    # Clean up keys and values\n",
    "    cleaned_tables = {\n",
    "        k.replace(' ', '').replace('表结构', ''): v.replace('--', '')\n",
    "        for k, v in parsed_tables.items()\n",
    "    }\n",
    "\n",
    "    # List of Chinese table names (keys)\n",
    "    chinese_table_names = list(cleaned_tables.keys())\n",
    "\n",
    "    name_map = map_chinese_to_english_tables(chinese_table_names, database_table_en)\n",
    "\n",
    "    table_maps = []\n",
    "    for cname, structure in cleaned_tables.items():\n",
    "        english_name = name_map.get(cname)\n",
    "        comments = find_value_in_list_of_dicts(database_L, '数据表名', english_name, '注释')\n",
    "\n",
    "        if question == '':\n",
    "            # No filtering, just return table name and structure\n",
    "            table_map = {\n",
    "                '数据表名': english_name,\n",
    "                '数据表结构': structure\n",
    "            }\n",
    "        else:\n",
    "            # Filter comments based on question\n",
    "            filtered_comments = filter_table_comments(question, comments)\n",
    "            table_map = {\n",
    "                '数据表名': english_name,\n",
    "                '数据表结构': structure,\n",
    "                '字段注释': filtered_comments\n",
    "            }\n",
    "\n",
    "        table_maps.append(table_map)\n",
    "\n",
    "    return table_maps\n",
    "\n",
    "\n",
    "def find_json(text):\n",
    "    \"\"\"\n",
    "    Attempt to extract and parse a JSON object from the provided text.\n",
    "    The function tries up to three attempts using two patterns:\n",
    "      1. A Markdown code block with ```json ... ```\n",
    "      2. A more general JSON-like pattern using { and }\n",
    "\n",
    "    If successful, returns the parsed JSON data.\n",
    "    If parsing fails after all attempts, returns the original text.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The input text from which to extract JSON.\n",
    "    \n",
    "    Returns:\n",
    "        dict or str: Parsed JSON dictionary if successful, else the original text.\n",
    "    \"\"\"\n",
    "    max_attempts = 3\n",
    "    for attempt in range(1, max_attempts + 1):\n",
    "        json_pattern = r\"```json\\n(.*?)\\n```\"\n",
    "        match = re.search(json_pattern, text, re.DOTALL)\n",
    "        if not match:\n",
    "            json_pattern2 = r\"({.*?})\"\n",
    "            match = re.search(json_pattern2, text, re.DOTALL)\n",
    "\n",
    "        if match:\n",
    "            json_string = match.group(1) if match.lastindex == 1 else match.group(0)\n",
    "            # Remove Markdown formatting if present\n",
    "            json_string = json_string.replace(\"```json\\n\", \"\").replace(\"\\n```\", \"\")\n",
    "            try:\n",
    "                data = json.loads(json_string)\n",
    "                return data\n",
    "            except json.JSONDecodeError as e:\n",
    "                if attempt < max_attempts:\n",
    "                    print(f\"Attempt {attempt}: Failed to parse JSON, reason: {e}. Retrying...\")\n",
    "                else:\n",
    "                    print(f\"All {max_attempts} attempts to parse JSON failed. Returning original text.\")\n",
    "        else:\n",
    "            if attempt < max_attempts:\n",
    "                print(f\"Attempt {attempt}: No JSON string found in the text. Retrying...\")\n",
    "            else:\n",
    "                print(\"No matching JSON string found. Returning original text.\")\n",
    "\n",
    "        # If no match or no success in this attempt, return the original text\n",
    "        return text\n",
    "\n",
    "\n",
    "def dict_to_sentence(data):\n",
    "    \"\"\"\n",
    "    Convert a dictionary into a descriptive sentence by enumerating key-value pairs.\n",
    "    For example: {\"name\": \"John\", \"age\": 30} -> \"name 是 John, age 是 30\"\n",
    "    \n",
    "    Parameters:\n",
    "        data (dict): The dictionary to convert.\n",
    "        \n",
    "    Returns:\n",
    "        str: A sentence describing the dictionary keys and values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not isinstance(data, dict):\n",
    "            raise ValueError(\"Input is not a dictionary\")\n",
    "\n",
    "        return \", \".join(f\"{key} 是 {value}\" for key, value in data.items())\n",
    "    except Exception as e:\n",
    "        print(f\"Error in dict_to_sentence: {e}\")\n",
    "        return str(data)\n",
    "\n",
    "\n",
    "def process_dict(d):\n",
    "    \"\"\"\n",
    "    Recursively process a nested dictionary to produce a comma-separated description.\n",
    "    For nested dictionaries, it processes them recursively and returns a descriptive string.\n",
    "    \n",
    "    For example:\n",
    "        {\n",
    "            \"company\": {\n",
    "                \"name\": \"ABC Corp\",\n",
    "                \"location\": \"New York\"\n",
    "            },\n",
    "            \"year\": 2021\n",
    "        }\n",
    "    might be processed into a string like:\n",
    "        \"company company 是 name 是 ABC Corp, location 是 New York, year 2021\"\n",
    "    \n",
    "    Parameters:\n",
    "        d (dict): A dictionary or another object to describe.\n",
    "        \n",
    "    Returns:\n",
    "        str: A descriptive string.\n",
    "    \"\"\"\n",
    "\n",
    "    def recursive_process(sub_dict):\n",
    "        sentences = []\n",
    "        for key, value in sub_dict.items():\n",
    "            if isinstance(value, dict):\n",
    "                # Process nested dictionary and wrap result in dict_to_sentence for formatting\n",
    "                nested_result = recursive_process(value)\n",
    "                sentences.append(dict_to_sentence({key: nested_result}))\n",
    "            else:\n",
    "                # Non-dict values are directly appended\n",
    "                sentences.append(f\"{key} {value}\")\n",
    "        return \", \".join(sentences)\n",
    "\n",
    "    if not isinstance(d, dict):\n",
    "        # If it's not a dictionary, just return its string representation\n",
    "        return str(d)\n",
    "\n",
    "    return recursive_process(d)\n",
    "\n",
    "\n",
    "def run_conversation(question):\n",
    "    \"\"\"\n",
    "    Run a conversation flow given a question by:\n",
    "      1. Using run_conversation_xietong(question) to get an answer.\n",
    "      2. Attempting to find and parse JSON from the answer using find_json.\n",
    "      3. Converting the parsed result (or original text if parsing fails) into a descriptive sentence using process_dict.\n",
    "    \n",
    "    Parameters:\n",
    "        question (str): The question to ask.\n",
    "        \n",
    "    Returns:\n",
    "        str: The final processed answer as a descriptive string.\n",
    "    \"\"\"\n",
    "    last_answer = run_conversation_xietong(question)\n",
    "    parsed_data = find_json(last_answer)\n",
    "    final_string = process_dict(parsed_data)\n",
    "    return final_string\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Remove any parenthetical segments (including Chinese parentheses) and trim whitespace.\n",
    "    For example, \"This is a sentence(remark)\" -> \"This is a sentence\"\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The text to clean.\n",
    "        \n",
    "    Returns:\n",
    "        str: The cleaned text.\n",
    "    \"\"\"\n",
    "    pattern = r'[\\(（][^\\)）]*[\\)）]'  # Pattern to match parentheses and their contents\n",
    "    cleaned_text = re.sub(pattern, '', text).strip()\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def find_dict_by_element(dict_list, target_element):\n",
    "    \"\"\"\n",
    "    Given a list of dictionaries, return all dictionaries where  '列名中文描述' contains the target_element.\n",
    "    Parameters:\n",
    "        dict_list (list): A list of dictionaries, each expected to have '列名中文描述' key.\n",
    "        target_element (str): The element to search for.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of dictionaries that contain target_element in '列名中文描述'.\n",
    "    \"\"\"\n",
    "    return [d for d in dict_list if target_element in d.get('列名中文描述', [])]\n",
    "\n",
    "\n",
    "def to_get_question_columns(question):\n",
    "    \"\"\"\n",
    "    Given a question (string) and a global variable database_L_zh (list of dicts),\n",
    "    find 列名 that correspond to 列名中文描述 mentioned in the question. \n",
    "    \n",
    "    If any matching columns are found, return a message instructing the user to \n",
    "    use these column names directly for data querying. If none are found, return an empty string.\n",
    "    \n",
    "    Parameters:\n",
    "        question (str): The input question text.\n",
    "        \n",
    "    Returns:\n",
    "        str: A message with identified column names or an empty string if none found.\n",
    "    \"\"\"\n",
    "    global database_L_zh\n",
    "    L_num = []\n",
    "    for items in database_L_zh:\n",
    "        L_num += items['列名中文描述']\n",
    "\n",
    "    # Get unique column descriptions\n",
    "    L_num_new = [item for item, count in Counter(L_num).items() if count == 1]\n",
    "\n",
    "    # Drop NaN if any\n",
    "    series_num = pd.Series(L_num_new)\n",
    "    L_num_new = list(series_num.dropna())\n",
    "\n",
    "    # Remove known irrelevant items\n",
    "    irrelevant_items = ['年度', '占比']\n",
    "    for irr in irrelevant_items:\n",
    "        if irr in L_num_new:\n",
    "            L_num_new.remove(irr)\n",
    "\n",
    "    matched_columns = []\n",
    "    for col_desc in L_num_new:\n",
    "        # Check if the column description or its cleaned version appears in the question\n",
    "        if col_desc in question or clean_text(col_desc) in question:\n",
    "            L_dict = find_dict_by_element(database_L_zh, col_desc)\n",
    "            if not L_dict:\n",
    "                continue\n",
    "            # Create a mapping from Chinese description to English column name\n",
    "            dict_zip = dict(zip(L_dict[0]['列名中文描述'], L_dict[0]['列名']))\n",
    "            column_name = dict_zip[col_desc]\n",
    "            data_table = L_dict[0]['数据表名']\n",
    "\n",
    "            matched_columns.append({\n",
    "                '数据库表': data_table,\n",
    "                '列名': column_name,\n",
    "                '列名中文含义': col_desc\n",
    "            })\n",
    "\n",
    "    if matched_columns:\n",
    "        return f\"已获得一部分数据库列名{matched_columns}，请充分利用获得的列名直接查询数据。\"\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af4fe1b",
   "metadata": {},
   "source": [
    "## sql优化\n",
    "\n",
    "本方案中需要对模型生成呢的SQL语句进行优化。我们对由模型生成的 SQL 语句进行一个小的优化步骤，以使其在查询接口中能够正确执行。主要的优化措施包括：\n",
    "\n",
    "1. 日期字段格式转换：函数 replace_date_with_day 会将形如 TradingDate = 'YYYY-MM-DD' 的条件自动转化为 date(TradingDate) = 'YYYY-MM-DD' 的格式。这样可以确保在特定查询引擎或数据库中根据日期进行正确的查询过滤。\n",
    "2. SQL语句提取: 函数 extract_sql 会从给定的文本中提取出被 sql ...  包围的 SQL 代码片段，从而从较复杂的文本中获得纯净的 SQL 语句。\n",
    "3. 接口查询执行：将优化后的 SQL 语句通过 select_data 函数发送到指定的 API 接口进行查询，并以 JSON 格式返回结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a92ea50a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T17:51:00.873389Z",
     "start_time": "2024-12-16T17:51:00.869030Z"
    }
   },
   "outputs": [],
   "source": [
    "def replace_date_with_day(sql):\n",
    "    \"\"\"\n",
    "    This function replaces instances of exact date conditions in a SQL \n",
    "    statement from a format like:\n",
    "        TradingDate = 'YYYY-MM-DD'\n",
    "    to:\n",
    "        date(TradingDate) = 'YYYY-MM-DD'\n",
    "    \n",
    "    Parameters:\n",
    "        sql (str): The original SQL statement.\n",
    "        \n",
    "    Returns:\n",
    "        str: The modified SQL statement, or the original if no match is found.\n",
    "    \"\"\"\n",
    "    # Regex pattern to match patterns like: ColumnName = 'YYYY-MM-DD'\n",
    "    pattern = r\"([.\\w]+)\\s*=\\s*'(\\d{4}-\\d{2}-\\d{2})'\"\n",
    "\n",
    "    def replace_func(match):\n",
    "        column_name = match.group(1)\n",
    "        date_value = match.group(2)\n",
    "        return f\"date({column_name}) = '{date_value}'\"\n",
    "\n",
    "    new_sql = re.sub(pattern, replace_func, sql)\n",
    "\n",
    "    # If no change was made, return the original SQL\n",
    "    return new_sql if new_sql != sql else sql\n",
    "\n",
    "\n",
    "def extract_sql(text):\n",
    "    \"\"\"\n",
    "    Extracts an SQL statement from a block of text enclosed in triple backticks:\n",
    "        ```sql\n",
    "        SELECT ...\n",
    "        ```\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The full text containing an SQL statement.\n",
    "        \n",
    "    Returns:\n",
    "        str: The extracted SQL statement, or a message if not found.\n",
    "    \"\"\"\n",
    "    sql_pattern = re.compile(r'```sql(.*?)```', re.DOTALL)\n",
    "    match = sql_pattern.search(text)\n",
    "    if match:\n",
    "        # Strip leading and trailing whitespace from the matched SQL\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return \"No SQL statement found.\"\n",
    "\n",
    "\n",
    "def select_data(sql_text):\n",
    "    \"\"\"\n",
    "    Sends the given SQL query to a specified endpoint and returns the JSON response.\n",
    "    \n",
    "    Parameters:\n",
    "        sql_text (str): The SQL query to be executed.\n",
    "        \n",
    "    Returns:\n",
    "        str: The JSON response from the API, formatted with indentation.\n",
    "    \"\"\"\n",
    "    url = \"https://comm.chatglm.cn/finglm2/api/query\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f'Bearer {Access_Token}'\n",
    "    }\n",
    "    data = {\n",
    "        \"sql\": sql_text,  # e.g. SELECT * FROM constantdb.secumain LIMIT 10\n",
    "        \"limit\": 15\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    try:\n",
    "        return json.dumps(response.json(), indent=2, ensure_ascii=False)\n",
    "    except:\n",
    "        return str(response.json())\n",
    "\n",
    "\n",
    "def to_select(text):\n",
    "    \"\"\"\n",
    "    High-level function that:\n",
    "      1. Extracts SQL from the given text.\n",
    "      2. Optimizes the extracted SQL by converting date columns to 'date(...)'.\n",
    "      3. Executes the optimized SQL through select_data and returns the result.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The input text containing an SQL statement.\n",
    "        \n",
    "    Returns:\n",
    "        str: The JSON response from the SQL query.\n",
    "    \"\"\"\n",
    "    sql_statement = extract_sql(text)\n",
    "    print('***********Extracted SQL****************')\n",
    "    print(sql_statement)\n",
    "    print('***********Extracted SQL****************')\n",
    "    optimized_sql = replace_date_with_day(sql_statement)\n",
    "    result = select_data(optimized_sql)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c648406d5c1e95c",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "预处理使用躺躺的方案，在这里进行了相关的解释说明。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bfaadee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T17:51:00.893508Z",
     "start_time": "2024-12-16T17:51:00.883971Z"
    }
   },
   "outputs": [],
   "source": [
    "def exec_sql_s(sql):\n",
    "    \"\"\"\n",
    "    Execute a given SQL query on a remote endpoint and return the result.\n",
    "    Uses 'Access_Token' for authorization and limits the result to 10 rows.\n",
    "\n",
    "    Parameters:\n",
    "        sql (str): The SQL query to be executed.\n",
    "\n",
    "    Returns:\n",
    "        list: The query result as a list of rows (dictionaries), or None if not found.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f'Bearer {Access_Token}',\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "    url = \"https://comm.chatglm.cn/finglm2/api/query\"\n",
    "\n",
    "    response = requests.post(url, headers=headers, json={\n",
    "        \"sql\": sql,\n",
    "        \"limit\": 10\n",
    "    })\n",
    "    response_json = response.json()\n",
    "\n",
    "    # If there's no 'data' field, print the full response for debugging\n",
    "    if 'data' not in response_json:\n",
    "        print(response_json)\n",
    "\n",
    "    # Return 'data' if present\n",
    "    return response_json.get('data', None)\n",
    "\n",
    "\n",
    "def output_result(result, info_list):\n",
    "    \"\"\"\n",
    "    Append the formatted JSON 'data' from the result into 'info_list'.\n",
    "\n",
    "    Parameters:\n",
    "        result (dict): The query result containing 'data'.\n",
    "        info_list (list): The list to which formatted data will be appended.\n",
    "\n",
    "    Returns:\n",
    "        list: The updated info_list with the new data appended, if any.\n",
    "    \"\"\"\n",
    "    if 'data' in result and len(result['data']) > 0:\n",
    "        info_list.append(json.dumps(result['data'], ensure_ascii=False, indent=1) + '\\n')\n",
    "    return info_list\n",
    "\n",
    "\n",
    "def process_company_name(value):\n",
    "    \"\"\"\n",
    "    Given a company name (or related keyword), search in three tables:\n",
    "    ConstantDB.SecuMain, ConstantDB.HK_SecuMain, ConstantDB.US_SecuMain.\n",
    "\n",
    "    Attempts to match various company-related fields (e.g., ChiName, EngName, etc.)\n",
    "    and returns all matching results along with the table where they were found.\n",
    "\n",
    "    Parameters:\n",
    "        value (str): The company name or related string to match.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples (result, table) where result is the matched data and table is the table name.\n",
    "              If no matches found, prints a message and returns an empty list.\n",
    "    \"\"\"\n",
    "    res_lst = []\n",
    "    tables = ['ConstantDB.SecuMain', 'ConstantDB.HK_SecuMain', 'ConstantDB.US_SecuMain']\n",
    "    columns_to_match = ['CompanyCode', 'SecuCode', 'ChiName', 'ChiNameAbbr',\n",
    "                        'EngName', 'EngNameAbbr', 'SecuAbbr', 'ChiSpelling']\n",
    "    columns_to_select = ['InnerCode', 'CompanyCode', 'SecuCode', 'ChiName', 'ChiNameAbbr',\n",
    "                         'EngName', 'EngNameAbbr', 'SecuAbbr', 'ChiSpelling']\n",
    "\n",
    "    # Escape single quotes to prevent SQL injection\n",
    "    value = value.replace(\"'\", \"''\")\n",
    "\n",
    "    for table in tables:\n",
    "        # For the US table, remove columns that may not be available\n",
    "        local_match_cols = columns_to_match.copy()\n",
    "        local_select_cols = columns_to_select.copy()\n",
    "        if 'US' in table:\n",
    "            if 'ChiNameAbbr' in local_match_cols:\n",
    "                local_match_cols.remove('ChiNameAbbr')\n",
    "            if 'ChiNameAbbr' in local_select_cols:\n",
    "                local_select_cols.remove('ChiNameAbbr')\n",
    "            if 'EngNameAbbr' in local_match_cols:\n",
    "                local_match_cols.remove('EngNameAbbr')\n",
    "            if 'EngNameAbbr' in local_select_cols:\n",
    "                local_select_cols.remove('EngNameAbbr')\n",
    "\n",
    "        # Build the WHERE clause with OR conditions for each column\n",
    "        match_conditions = [f\"{col} = '{value}'\" for col in local_match_cols]\n",
    "        where_clause = ' OR '.join(match_conditions)\n",
    "\n",
    "        sql = f\"\"\"\n",
    "        SELECT {', '.join(local_select_cols)}\n",
    "        FROM {table}\n",
    "        WHERE {where_clause}\n",
    "        \"\"\"\n",
    "        result = exec_sql_s(sql)\n",
    "        if result:\n",
    "            res_lst.append((result, table))\n",
    "    else:\n",
    "        # The 'else' clause in a for loop runs only if no 'break' was encountered.\n",
    "        # Here it just prints if no results were found.\n",
    "        if not res_lst:\n",
    "            print(f\"未在任何表中找到公司名称为 {value} 的信息。\")\n",
    "\n",
    "    return res_lst\n",
    "\n",
    "\n",
    "def process_code(value):\n",
    "    \"\"\"\n",
    "    Given a code (e.g., a stock code), search the three tables and return matches.\n",
    "\n",
    "    Parameters:\n",
    "        value (str): The code to search for.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples (result, table) if found, else empty.\n",
    "    \"\"\"\n",
    "    res_lst = []\n",
    "    tables = ['ConstantDB.SecuMain', 'ConstantDB.HK_SecuMain', 'ConstantDB.US_SecuMain']\n",
    "    columns_to_select = ['InnerCode', 'CompanyCode', 'SecuCode', 'ChiName', 'ChiNameAbbr',\n",
    "                         'EngName', 'EngNameAbbr', 'SecuAbbr', 'ChiSpelling']\n",
    "\n",
    "    value = value.replace(\"'\", \"''\")  # Escape single quotes\n",
    "\n",
    "    for table in tables:\n",
    "        local_select_cols = columns_to_select.copy()\n",
    "        if 'US' in table:\n",
    "            if 'ChiNameAbbr' in local_select_cols:\n",
    "                local_select_cols.remove('ChiNameAbbr')\n",
    "            if 'EngNameAbbr' in local_select_cols:\n",
    "                local_select_cols.remove('EngNameAbbr')\n",
    "\n",
    "        sql = f\"\"\"\n",
    "        SELECT {', '.join(local_select_cols)}\n",
    "        FROM {table}\n",
    "        WHERE SecuCode = '{value}'\n",
    "        \"\"\"\n",
    "        result = exec_sql_s(sql)\n",
    "        if result:\n",
    "            res_lst.append((result, table))\n",
    "    else:\n",
    "        if not res_lst:\n",
    "            print(f\"未在任何表中找到代码为 {value} 的信息。\")\n",
    "\n",
    "    return res_lst\n",
    "\n",
    "\n",
    "def process_items(item_list):\n",
    "    \"\"\"\n",
    "    Given a list of items (dictionaries) from JSON extraction, attempt to process each based on its key:\n",
    "    - If key is '基金名称' or '公司名称', use process_company_name.\n",
    "    - If key is '代码', use process_code.\n",
    "    - Otherwise, print an unrecognized key message.\n",
    "\n",
    "    Parameters:\n",
    "        item_list (list): A list of dictionaries like [{\"公司名称\": \"XX公司\"}, {\"代码\":\"600872\"}].\n",
    "\n",
    "    Returns:\n",
    "        tuple: (res, tables)\n",
    "               res (str): A formatted string showing what was found.\n",
    "               tables (list): A list of table names where matches were found.\n",
    "    \"\"\"\n",
    "    res_list = []\n",
    "    for item in item_list:\n",
    "        key, value = list(item.items())[0]\n",
    "        if key in [\"基金名称\", \"公司名称\"]:\n",
    "            res_list.extend(process_company_name(value))\n",
    "        elif key == \"代码\":\n",
    "            res_list.extend(process_code(value))\n",
    "        else:\n",
    "            print(f\"无法识别的键：{key}\")\n",
    "\n",
    "    # Filter out empty results\n",
    "    res_list = [i for i in res_list if i]\n",
    "    res = ''\n",
    "    tables = []\n",
    "    for result_data, table_name in res_list:\n",
    "        tables.append(table_name)\n",
    "        res += f\"预处理程序通过表格：{table_name} 查询到以下内容：\\n {json.dumps(result_data, ensure_ascii=False, indent=1)} \\n\"\n",
    "\n",
    "    return res, tables\n",
    "\n",
    "\n",
    "def extract_list_from_json(json_string):\n",
    "    \"\"\"\n",
    "    Attempt to decode a JSON string representing a list.\n",
    "\n",
    "    Parameters:\n",
    "        json_string (str): The JSON string to decode.\n",
    "\n",
    "    Returns:\n",
    "        list or None: The decoded list, or None if decoding fails or not a list.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = json.loads(json_string)\n",
    "        if isinstance(data, list):\n",
    "            return data\n",
    "        else:\n",
    "            print(\"解码的JSON数据不是一个列表\")\n",
    "            return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON解码错误: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_question(question):\n",
    "    \"\"\"\n",
    "    Given a question, run it through a prompt to perform Named Entity Recognition (NER),\n",
    "    extract entities (公司名称, 代码, 基金名称), parse the assistant's JSON response,\n",
    "    and process the items to retrieve relevant information from the database.\n",
    "\n",
    "    Parameters:\n",
    "        question (str): The user question.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (res, tables) where\n",
    "               res (str) - Processed result details as a string.\n",
    "               tables (list) - List of tables involved in the final result.\n",
    "    \"\"\"\n",
    "    prompt = '''\n",
    "    你将会进行命名实体识别任务，并输出实体json，主要识别以下几种实体：\n",
    "    公司名称，代码，基金名称。\n",
    "\n",
    "    其中，公司名称可以是全称，简称，拼音缩写，代码包含股票代码和基金代码，基金名称包含债券型基金，\n",
    "    以下是几个示例：\n",
    "    user:唐山港集团股份有限公司是什么时间上市的（回答XXXX-XX-XX）\n",
    "    当年一共上市了多少家企业？\n",
    "    这些企业有多少是在北京注册的？\n",
    "    assistant:```json\n",
    "    [{\"公司名称\":\"唐山港集团股份有限公司\"}]\n",
    "    ```\n",
    "    user:JD的职工总数有多少人？\n",
    "    该公司披露的硕士或研究生学历（及以上）的有多少人？\n",
    "    20201月1日至年底退休了多少人？\n",
    "    assistant:```json\n",
    "    [{\"公司名称\":\"JD\"}]\n",
    "    ```\n",
    "    user:600872的全称、A股简称、法人、法律顾问、会计师事务所及董秘是？\n",
    "    该公司实控人是否发生改变？如果发生变化，什么时候变成了谁？是哪国人？是否有永久境外居留权？（回答时间用XXXX-XX-XX）\n",
    "    assistant:```json\n",
    "    [{\"代码\":\"600872\"}]\n",
    "    ```\n",
    "    user:华夏鼎康债券A在2019年的分红次数是多少？每次分红的派现比例是多少？\n",
    "    基于上述分红数据，在2019年最后一次分红时，如果一位投资者持有1000份该基金，税后可以获得多少分红收益？\n",
    "    assistant:```json\n",
    "    [{\"基金名称\":\"华夏鼎康债券A\"}]\n",
    "    ```\n",
    "    user:化工纳入过多少个子类概念？\n",
    "    assistant:```json\n",
    "    []\n",
    "    ```\n",
    "    '''\n",
    "\n",
    "    messages = [{'role': 'system', 'content': prompt}, {'role': 'user', 'content': question}]\n",
    "    aa = create_chat_completion(messages)\n",
    "    bb = find_json(aa.choices[0].message.content)\n",
    "    return process_items(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da782db3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T17:51:00.923096Z",
     "start_time": "2024-12-16T17:51:00.914738Z"
    }
   },
   "outputs": [],
   "source": [
    "def way_string_2(question):\n",
    "    way_string_2 = to_get_question_columns(question)\n",
    "    way_string_2 += \">>查询参考：\"\n",
    "    if \"近一个月最高价\" in question:\n",
    "        way_string_2 += \"查询近一个月最高价,你写的sql语句可以优先考虑表中已有字段HighPriceRM  近一月最高价(元)  \"\n",
    "    if \"近一个月最低价\" in question:\n",
    "        way_string_2 += \"查询近一月最低价(元),你写的sql语句直接调用已有字段LowPriceRM\"\n",
    "    if \"行业\" in question and ('多少只' in question or '几个' in question or '多少个' in question):\n",
    "        way_string_2 += \"\"\"查询某行业某年数量 示例sql语句:SELECT count(*) as 风电零部件_2021\n",
    "            FROM AStockIndustryDB.LC_ExgIndustry\n",
    "            where ThirdIndustryName like '%风电零部件%' and year(InfoPublDate)=2021 and IfPerformed = 1;\"\"\"\n",
    "    if ('年度报告' in question and '最新更新' in question) or '比例合计' in question:\n",
    "        way_string_2 += \"\"\"特别重要一定注意，查询最新更新XXXX年年度报告，机构持有无限售流通A股数量合计InstitutionsHoldProp最多公司代码，优先使用查询sql语句，SELECT *\n",
    "                            FROM AStockShareholderDB.LC_StockHoldingSt\n",
    "                            WHERE date(EndDate) = 'XXXX-12-31'\n",
    "                              AND UpdateTime = (\n",
    "                                SELECT MAX(UpdateTime)\n",
    "                                FROM AStockShareholderDB.LC_StockHoldingSt\n",
    "                                WHERE date(EndDate) = 'XXXX-12-31'\n",
    "                              ) order by InstitutionsHoldings desc limit 1 ，XXXX代表问题查询年度，sql语句禁止出现group by InnerCode;\n",
    "\n",
    "                              查询最新更新XXXX年年度报告,公司机构持有无限售流通A股比例合计InstitutionsHoldProp是多少,优先使用查询sql语句，SELECT InstitutionsHoldProp\n",
    "                            FROM AStockShareholderDB.LC_StockHoldingSt\n",
    "                            WHERE date(EndDate) = 'XXXX-12-31'\n",
    "                              AND UpdateTime = (\n",
    "                                SELECT MAX(UpdateTime)\n",
    "                                FROM AStockShareholderDB.LC_StockHoldingSt\n",
    "                                WHERE date(EndDate) = 'XXXX-12-31'\n",
    "                              ) order by InstitutionsHoldings desc limit 1 ，XXXX代表问题查询年度，sql语句禁止出现group by InnerCode;\"\"\"\n",
    "\n",
    "    if '新高' in question:\n",
    "        way_string_2 += \"\"\"新高 要用AStockMarketQuotesDB.CS_StockPatterns现有字段\n",
    "        \n",
    "        查询今天是2021年01月01日，创近半年新高的股票有几只示。示例sql语句:SELECT count(*)  FROM AStockMarketQuotesDB.CS_StockPatterns\n",
    "                where  IfHighestHPriceRMSix=1 and date(TradingDay)='2021-01-01;\n",
    "                判断某日 YY-MM-DD  InnerCode XXXXXX 是否创近一周的新高，查询结果1代表是,IfHighestHPriceRW字段可以根据情况灵活调整  SELECT   InnerCode,TradingDay,IfHighestHPriceRW  FROM AStockMarketQuotesDB.CS_StockPatterns\n",
    "where  date(TradingDay)='2021-12-20' and InnerCode = '311490'\n",
    "                \n",
    "                \"\"\"\n",
    "    if '成交额' in question and '平均' in question:\n",
    "        way_string_2 += \"\"\"查询这家公司5日内平均成交额是多少。示例sql语句:SELECT count(*)  FROM AStockMarketQuotesDB.CS_StockPatterns\n",
    "                where  IfHighestHPriceRMSix=1 and date(TradingDay)='2021-01-01\"\"\"\n",
    "    if '半年度报告' in question:\n",
    "        way_string_2 += \"\"\"查询XXXX年半年度报告的条件为：year(EndDate) = XXXX and InfoSource='半年度报告'\"\"\"\n",
    "\n",
    "    if '新高' in question:\n",
    "        way_string_2 += \"\"\"查询今天是2021年01月01日，创近半年新高的股票有几只示。示例sql语句:SELECT count(*)  FROM AStockMarketQuotesDB.CS_StockPatterns\n",
    "                where  IfHighestHPriceRMSix=1 and date(TradingDay)='2021-01-01\"\"\"\n",
    "    if '成交额' in question and '平均' in question:\n",
    "        way_string_2 += \"\"\"查询这家公司5日内平均成交额是多少。示例sql语句:SELECT count(*)  FROM AStockMarketQuotesDB.CS_StockPatterns\n",
    "                where  IfHighestHPriceRMSix=1 and date(TradingDay)='2021-01-01\"\"\"\n",
    "\n",
    "    return way_string_2\n",
    "\n",
    "\n",
    "def run_conversation_until_complete(messages, max_rounds=6):\n",
    "    \"\"\"\n",
    "    Test function to run a conversation loop until the assistant indicates completion.\n",
    "    \"\"\"\n",
    "    last_response = None  # 用于存储最后一次对话的响应\n",
    "    round_count = 0  # 对话轮数计数器\n",
    "    response = create_chat_completion(messages)\n",
    "    while True:\n",
    "        if round_count >= max_rounds:\n",
    "            break  # 如果对话轮数超过最大值，则退出循环\n",
    "\n",
    "        question = response.choices[0].message.content\n",
    "        select_result = to_select(question)\n",
    "        messages.append({\"role\": \"assistant\", \"content\": question})\n",
    "        messages.append({\"role\": \"user\", \"content\": str(select_result)})\n",
    "\n",
    "        response = create_chat_completion(messages)\n",
    "\n",
    "        last_response = response.choices[0].message.content  # 存储最后一次响应       \n",
    "        if \"全部完成\" in response.choices[0].message.content:\n",
    "            break  # 如果检测到“回答完成”，则停止循环\n",
    "        round_count += 1  # 增加对话轮数计数\n",
    "    return last_response  # 返回最后一次对话的内容\n",
    "\n",
    "\n",
    "def run_conversation_xietong(question):\n",
    "    content_p_1 = \"\"\"我有如下数据库表{'库表名': ['AStockBasicInfoDB.LC_StockArchives',\n",
    "  'AStockBasicInfoDB.LC_NameChange',\n",
    "  'AStockBasicInfoDB.LC_Business',\n",
    "  'AStockIndustryDB.LC_ExgIndustry',\n",
    "  'AStockIndustryDB.LC_ExgIndChange',\n",
    "  'AStockIndustryDB.LC_IndustryValuation',\n",
    "  'AStockIndustryDB.LC_IndFinIndicators',\n",
    "  'AStockIndustryDB.LC_COConcept',\n",
    "  'AStockIndustryDB.LC_ConceptList',\n",
    "  'AStockOperationsDB.LC_SuppCustDetail',\n",
    "  'AStockShareholderDB.LC_SHTypeClassifi',\n",
    "  'AStockShareholderDB.LC_MainSHListNew',\n",
    "  'AStockShareholderDB.LC_SHNumber',\n",
    "  'AStockShareholderDB.LC_Mshareholder',\n",
    "  'AStockShareholderDB.LC_ActualController',\n",
    "  'AStockShareholderDB.LC_ShareStru',\n",
    "  'AStockShareholderDB.LC_StockHoldingSt',\n",
    "  'AStockShareholderDB.LC_ShareTransfer',\n",
    "  'AStockShareholderDB.LC_ShareFP',\n",
    "  'AStockShareholderDB.LC_ShareFPSta',\n",
    "  'AStockShareholderDB.LC_Buyback',\n",
    "  'AStockShareholderDB.LC_BuybackAttach',\n",
    "  'AStockShareholderDB.LC_LegalDistribution',\n",
    "  'AStockShareholderDB.LC_NationalStockHoldSt',\n",
    "  'AStockShareholderDB.CS_ForeignHoldingSt',\n",
    "  'AStockFinanceDB.LC_AShareSeasonedNewIssue',\n",
    "  'AStockFinanceDB.LC_ASharePlacement',\n",
    "  'AStockFinanceDB.LC_Dividend',\n",
    "  'AStockFinanceDB.LC_CapitalInvest',\n",
    "  'AStockMarketQuotesDB.CS_StockCapFlowIndex',\n",
    "  'AStockMarketQuotesDB.CS_TurnoverVolTecIndex',\n",
    "  'AStockMarketQuotesDB.CS_StockPatterns',\n",
    "  'AStockMarketQuotesDB.QT_DailyQuote',\n",
    "  'AStockMarketQuotesDB.QT_StockPerformance',\n",
    "  'AStockMarketQuotesDB.LC_SuspendResumption',\n",
    "  'AStockFinanceDB.LC_BalanceSheetAll',\n",
    "  'AStockFinanceDB.LC_IncomeStatementAll',\n",
    "  'AStockFinanceDB.LC_CashFlowStatementAll',\n",
    "  'AStockFinanceDB.LC_IntAssetsDetail',\n",
    "  'AStockFinanceDB.LC_MainOperIncome',\n",
    "  'AStockFinanceDB.LC_OperatingStatus',\n",
    "  'AStockFinanceDB.LC_AuditOpinion',\n",
    "  'AStockOperationsDB.LC_Staff',\n",
    "  'AStockOperationsDB.LC_RewardStat',\n",
    "  'AStockEventsDB.LC_Warrant',\n",
    "  'AStockEventsDB.LC_Credit',\n",
    "  'AStockEventsDB.LC_SuitArbitration',\n",
    "  'AStockEventsDB.LC_EntrustInv',\n",
    "  'AStockEventsDB.LC_Regroup',\n",
    "  'AStockEventsDB.LC_MajorContract',\n",
    "  'AStockEventsDB.LC_InvestorRa',\n",
    "  'AStockEventsDB.LC_InvestorDetail',\n",
    "  'AStockShareholderDB.LC_ESOP',\n",
    "  'AStockShareholderDB.LC_ESOPSummary',\n",
    "  'AStockShareholderDB.LC_TransferPlan',\n",
    "  'AStockShareholderDB.LC_SMAttendInfo',\n",
    "  'HKStockDB.HK_EmployeeChange',\n",
    "  'HKStockDB.HK_StockArchives',\n",
    "  'HKStockDB.CS_HKStockPerformance',\n",
    "  'USStockDB.US_CompanyInfo',\n",
    "  'USStockDB.US_DailyQuote',\n",
    "  'PublicFundDB.MF_FundArchives',\n",
    "  'PublicFundDB.MF_FundProdName',\n",
    "  'PublicFundDB.MF_InvestAdvisorOutline',\n",
    "  'PublicFundDB.MF_Dividend',\n",
    "  'CreditDB.LC_ViolatiParty',\n",
    "  'IndexDB.LC_IndexBasicInfo',\n",
    "  'IndexDB.LC_IndexComponent',\n",
    "  'InstitutionDB.LC_InstiArchive',\n",
    "  'ConstantDB.SecuMain',\n",
    "  'ConstantDB.HK_SecuMain',\n",
    "  'ConstantDB.CT_SystemConst',\n",
    "  'ConstantDB.QT_TradingDayNew',\n",
    "  'ConstantDB.LC_AreaCode',\n",
    "  'InstitutionDB.PS_EventStru',\n",
    "  'ConstantDB.US_SecuMain',\n",
    "  'InstitutionDB.PS_NewsSecurity'],\n",
    " '对应中文注释说明': ['公司概况',\n",
    "  '公司名称更改状况',\n",
    "  '公司经营范围与行业变更',\n",
    "  '公司行业划分表',\n",
    "  '公司行业变更表',\n",
    "  '行业估值指标',\n",
    "  '行业财务指标表',\n",
    "  '概念所属公司表',\n",
    "  '概念板块常量表',\n",
    "  '公司供应商与客户',\n",
    "  '股东类型分类表',\n",
    "  '股东名单(新)',\n",
    "  '股东户数',\n",
    "  '大股东介绍',\n",
    "  '公司实际控制人',\n",
    "  '公司股本结构变动',\n",
    "  '股东持股统计',\n",
    "  '股东股权变动',\n",
    "  '股东股权冻结和质押',\n",
    "  '股东股权冻结和质押统计',\n",
    "  '股份回购',\n",
    "  '股份回购关联表',\n",
    "  '法人配售与战略投资者',\n",
    "  'A股国家队持股统计',\n",
    "  '外资持股统计',\n",
    "  'A股增发',\n",
    "  'A股配股',\n",
    "  '公司分红',\n",
    "  '资金投向说明',\n",
    "  '境内股票交易资金流向指标',\n",
    "  '境内股票成交量技术指标',\n",
    "  '股票技术形态表',\n",
    "  '日行情表',\n",
    "  '股票行情表现(新)',\n",
    "  '停牌复牌表',\n",
    "  '资产负债表_新会计准则',\n",
    "  '利润分配表_新会计准则',\n",
    "  '现金流量表_新会计准则',\n",
    "  '公司研发投入与产出',\n",
    "  '公司主营业务构成',\n",
    "  '公司经营情况述评',\n",
    "  '公司历年审计意见',\n",
    "  '公司职工构成',\n",
    "  '公司管理层报酬统计',\n",
    "  '公司担保明细',\n",
    "  '公司借贷明细',\n",
    "  '公司诉讼仲裁明细',\n",
    "  '重大事项委托理财',\n",
    "  '公司资产重组明细',\n",
    "  '公司重大经营合同明细',\n",
    "  '投资者关系活动',\n",
    "  '投资者关系活动调研明细',\n",
    "  '员工持股计划',\n",
    "  '员工持股计划概况',\n",
    "  '股东增减持计划表',\n",
    "  '股东大会出席信息',\n",
    "  '港股公司员工数量变动表',\n",
    "  '港股公司概况',\n",
    "  '港股行情表现',\n",
    "  '美股公司概况',\n",
    "  '美股日行情',\n",
    "  '公募基金概况',\n",
    "  '公募基金产品名称',\n",
    "  '公募基金管理人概况',\n",
    "  '公募基金分红',\n",
    "  '违规当事人处罚',\n",
    "  '指数基本情况',\n",
    "  '指数成份',\n",
    "  '机构基本资料',\n",
    "  '证券主表,包含字段InnerCode,CompanyCode,SecuCode,ChiName,ChiNameAbbr 代表中文名称缩写,EngName,EngNameAbbr,SecuAbbr 代表 证券简称,ListedDate',\n",
    "  '港股证券主表，包含字段InnerCode,CompanyCode,SecuCode,ChiName,ChiNameAbbr 代表中文名称缩写,EngName,EngNameAbbr,SecuAbbr 代表 证券简称,ListedDate',\n",
    "  '系统常量表',\n",
    "  '交易日表(新)',\n",
    "  '国家城市代码表',\n",
    "  '事件体系指引表',\n",
    "  '美股证券主表',\n",
    "  '证券舆情表']}\n",
    "已查询获得事实：<<fact_1>>\n",
    "我想回答问题\n",
    "\"<<question>>\"\n",
    "\n",
    "如果已查询获得事实可以直接总结答案，需要是明确的答案数据不是需要查询数据库表，记得提示我：<全部完成，答案如下>,将答案总结以json格式给我。\n",
    "如果不能直接总结答案，需要查询的数据库表,请从上面数据库表中筛选出还需要哪些数据库表，记得提示我：<需要查询的数据库表>,只返回需要数据列表,不要回答其他内容。\"\"\"\n",
    "\n",
    "    content_p = content_p_1.replace('<<question>>', str(question)).replace('<<fact_1>>',\n",
    "                                                                           str(process_question(question)))\n",
    "    content_p = content_p + way_string_2(question)\n",
    "    content_p_2 = \"\"\"获取的表结构如下<list>,表结构中列名可以引用使用,表结构中数据示例只是参考不能引用。\n",
    "我们现在开始查询当前问题，请你分步写出查询sql语句，我把查询结果告诉你，你再告诉我下一步，\n",
    "注意如果我返回的结果为空或者错误影响下一步调用，请重新告诉我sql语句。\n",
    "等你全部回答完成，不需要进行下一步调用时，记得提示我：<全部完成，答案如下>,将答案总结以json格式给我，只需要总结当前问题。\n",
    "查询技巧:sql查询年度时优先使用year()函数。sql查询语句不需要注释，不然会报错。sql中日期条件格式应参考这样date(TradingDay) = 'YYYY-MM-DD'。尽量利用表格中已有的字段。\"\"\"\n",
    "\n",
    "    # 执行函数部分\n",
    "    messages = []\n",
    "    # messages.append({\"role\": \"user\", \"content\": \"您好阿\"})\n",
    "    messages.append({\"role\": \"user\", \"content\": content_p})\n",
    "    response = create_chat_completion(messages)\n",
    "    if \"全部完成\" in response.choices[0].message.content:\n",
    "        return response.choices[0].message.content  # 如果检测到“回答完成”，则停止循环\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "    table_maps = get_table_schema(question)\n",
    "    LL = [i for i in table_maps if i.get('数据表名') in response.choices[0].message.content]\n",
    "    content_p_2 = content_p_2.replace('<list>', str(LL)) + way_string_2(question)\n",
    "    messages.append({\"role\": \"user\", \"content\": content_p_2})  ###开始对话       \n",
    "    last_answer = run_conversation_until_complete(messages, max_rounds=9)\n",
    "    return last_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a9d74e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 运行脚本解决问题\n",
    "这里展现了对单个问题的完整流程。主程序将会遍历这个过程，直到完成所有问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a625550a-f070-4bda-9ab2-aca7216ec591",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T17:51:00.943496Z",
     "start_time": "2024-12-16T17:51:00.936071Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_answer(question):\n",
    "    \"\"\"\n",
    "    Attempt to answer the given question by interacting with the \n",
    "    conversation model. If an error occurs, return a default error message.\n",
    "    \n",
    "    Parameters:\n",
    "        question (str): The question that needs an answer.\n",
    "        \n",
    "    Returns:\n",
    "        str: The answer string or an error message if an exception occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Attempting to answer the question: {question}\")\n",
    "        last_answer = run_conversation(question)\n",
    "        return last_answer\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while executing get_answer: {e}\")\n",
    "        return \"An error occurred while retrieving the answer.\"\n",
    "\n",
    "\n",
    "def question_rew(context_text, original_question):\n",
    "    \"\"\"\n",
    "    Rewrite the given question to be clearer and more specific based on the provided context,\n",
    "    without altering the original meaning or omitting any information.\n",
    "    \n",
    "    Parameters:\n",
    "        context_text (str): The context text that the question is based on.\n",
    "        original_question (str): The question to be rewritten.\n",
    "        \n",
    "    Returns:\n",
    "        str: The rewritten question.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        f\"根据这些内容'{context_text}',帮我重写这个问题”'{original_question}' ,让问题清晰明确，\"\n",
    "        \"不改变原意，不要遗漏信息，特别是时间，只返回问题。\\n\"\n",
    "        \"以下是示例：\\n\"\n",
    "        \"user:根据这些内容'最新更新的2021年度报告中，机构持有无限售流通A股数量合计最多的公司简称是？  公司简称 帝尔激光',\"\n",
    "        \"帮我重写这个问题'在这份报告中，该公司机构持有无限售流通A股比例合计是多少，保留2位小数？' ,让问题清晰明确，不改变原意，不要遗漏信息，特别是时间，\"\n",
    "        \"只返回问题。\\n\"\n",
    "        \"assistant:最新更新的2021年度报告中,公司简称 帝尔激光 持有无限售流通A股比例合计是多少，保留2位小数？\"\n",
    "    )\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = create_chat_completion(messages)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def main_answer(q_json_list, start_index=0, end_index=None):\n",
    "    \"\"\"\n",
    "    Process a portion of a list of JSON objects, each containing a 'tid' and 'team' \n",
    "    where 'team' is a list of questions.\n",
    "    \n",
    "    For each JSON object in the specified range:\n",
    "      1. Extract all questions from 'team'.\n",
    "      2. If no previous Q&A history, use the question directly. Otherwise, \n",
    "         rewrite the question based on all previously answered content.\n",
    "      3. Get the answer using get_answer and store it.\n",
    "      4. Update the original structure with the answers.\n",
    "    \n",
    "    Parameters:\n",
    "        q_json_list (list): List of data objects, each containing keys 'tid' and 'team'.\n",
    "        start_index (int): The starting index of the list subset to process.\n",
    "        end_index (int): The ending index (non-inclusive) of the list subset. \n",
    "                         If None, process until the end of q_json_list.\n",
    "                         \n",
    "    Returns:\n",
    "        list: A list of processed dictionaries with updated answers.\n",
    "    \"\"\"\n",
    "    if end_index is None or end_index > len(q_json_list):\n",
    "        end_index = len(q_json_list)\n",
    "\n",
    "    data_list_result = []\n",
    "    for i in tqdm(range(start_index, end_index), desc=\"Processing JSON data in range\"):\n",
    "        item = q_json_list[i]\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Extract questions\n",
    "        questions_list = [(member[\"id\"], member[\"question\"]) for member in item[\"team\"]]\n",
    "        answers_dict = {}\n",
    "        all_previous = ''\n",
    "\n",
    "        # Iterate over all questions in the current item\n",
    "        for question_id, question_text in questions_list:\n",
    "            if all_previous == '':\n",
    "                rewritten_question = question_text\n",
    "            else:\n",
    "                rewritten_question = question_rew(all_previous, question_text)\n",
    "\n",
    "            answer = get_answer(rewritten_question)\n",
    "            print(f'----------answer:{answer}')\n",
    "            answers_dict[question_id] = answer\n",
    "            all_previous += question_text + answer\n",
    "\n",
    "        # Update original item with answers\n",
    "        for member in item[\"team\"]:\n",
    "            member[\"answer\"] = answers_dict.get(member[\"id\"], \"无答案\")\n",
    "\n",
    "        updated_data = {\"tid\": item[\"tid\"], \"team\": item[\"team\"]}\n",
    "        data_list_result.append(updated_data)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Completed processing JSON index {i} in {elapsed_time:.2f} seconds\")\n",
    "        with open('result_zj.json', 'w', encoding='utf-8') as json_file:\n",
    "            json.dump(data_list_result, json_file, ensure_ascii=False, indent=4)\n",
    "    return data_list_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc88ecdcfc54c52",
   "metadata": {},
   "source": [
    "## 主代码\n",
    "运行下列代码块，就能运行完整的整个项目，本NoteBook未启用并发，因此效率较低，运行所有问题需要使用大约3小时时间。如果你只希望运行于几道题，你可以在参数中进行设置，比如只运行前面两题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e69420fbe6ce82b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T17:51:37.706817Z",
     "start_time": "2024-12-16T17:51:00.951854Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSON data in range:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to answer the question: 600872的全称、A股简称、法人、法律顾问、会计师事务所及董秘是？\n",
      "{'detail': 'Invalid authentication credentials'}\n",
      "{'detail': 'Invalid authentication credentials'}\n",
      "{'detail': 'Invalid authentication credentials'}\n",
      "未在任何表中找到代码为 600872 的信息。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/vb/vfysl1s55bq8fx84fr_g92xm0000gn/T/jieba.cache\n",
      "Loading model cost 0.279 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Extracted SQL****************\n",
      "SELECT ChiName AS '全称', AShareAbbr AS 'A股简称', LegalRepr AS '法人', LegalConsultant AS '法律顾问', AccountingFirm AS '会计师事务所', SecretaryBD AS '董秘'\n",
      "FROM AStockBasicInfoDB.LC_StockArchives\n",
      "WHERE AStockCode = '600872';\n",
      "***********Extracted SQL****************\n",
      "***********Extracted SQL****************\n",
      "No SQL statement found.\n",
      "***********Extracted SQL****************\n",
      "***********Extracted SQL****************\n",
      "No SQL statement found.\n",
      "***********Extracted SQL****************\n",
      "***********Extracted SQL****************\n",
      "No SQL statement found.\n",
      "***********Extracted SQL****************\n",
      "***********Extracted SQL****************\n",
      "No SQL statement found.\n",
      "***********Extracted SQL****************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSON data in range:   0%|          | 0/1 [00:26<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m start_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m end_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Specify processing data in the range 0-101\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmain_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_json_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Write the processing results to a file\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult-2.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n",
      "Cell \u001b[0;32mIn[9], line 89\u001b[0m, in \u001b[0;36mmain_answer\u001b[0;34m(q_json_list, start_index, end_index)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     rewritten_question \u001b[38;5;241m=\u001b[39m question_rew(all_previous, question_text)\n\u001b[0;32m---> 89\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mget_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrewritten_question\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----------answer:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     91\u001b[0m answers_dict[question_id] \u001b[38;5;241m=\u001b[39m answer\n",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m, in \u001b[0;36mget_answer\u001b[0;34m(question)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to answer the question: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m     last_answer \u001b[38;5;241m=\u001b[39m \u001b[43mrun_conversation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m last_answer\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[5], line 313\u001b[0m, in \u001b[0;36mrun_conversation\u001b[0;34m(question)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_conversation\u001b[39m(question):\n\u001b[1;32m    301\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;124;03m    Run a conversation flow given a question by:\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;124;03m      1. Using run_conversation_xietong(question) to get an answer.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;124;03m        str: The final processed answer as a descriptive string.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m     last_answer \u001b[38;5;241m=\u001b[39m \u001b[43mrun_conversation_xietong\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m     parsed_data \u001b[38;5;241m=\u001b[39m find_json(last_answer)\n\u001b[1;32m    315\u001b[0m     final_string \u001b[38;5;241m=\u001b[39m process_dict(parsed_data)\n",
      "Cell \u001b[0;32mIn[8], line 264\u001b[0m, in \u001b[0;36mrun_conversation_xietong\u001b[0;34m(question)\u001b[0m\n\u001b[1;32m    262\u001b[0m content_p_2 \u001b[38;5;241m=\u001b[39m content_p_2\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<list>\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(LL)) \u001b[38;5;241m+\u001b[39m way_string_2(question)\n\u001b[1;32m    263\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: content_p_2})  \u001b[38;5;66;03m###开始对话       \u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m last_answer \u001b[38;5;241m=\u001b[39m \u001b[43mrun_conversation_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m last_answer\n",
      "Cell \u001b[0;32mIn[8], line 72\u001b[0m, in \u001b[0;36mrun_conversation_until_complete\u001b[0;34m(messages, max_rounds)\u001b[0m\n\u001b[1;32m     69\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: question})\n\u001b[1;32m     70\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(select_result)})\n\u001b[0;32m---> 72\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_chat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m last_response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent  \u001b[38;5;66;03m# 存储最后一次响应       \u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m全部完成\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent:\n",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m, in \u001b[0;36mcreate_chat_completion\u001b[0;34m(messages, model)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_chat_completion\u001b[39m(messages, model\u001b[38;5;241m=\u001b[39mMODEL):\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    Create a chat completion using the provided messages and model.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m        response (dict): The response from the chat completion endpoint.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm_api/lib/python3.10/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm_api/lib/python3.10/site-packages/openai/resources/chat/completions.py:829\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    826\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    827\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    828\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm_api/lib/python3.10/site-packages/openai/_base_client.py:1280\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1268\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1275\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1277\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1278\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1279\u001b[0m     )\n\u001b[0;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm_api/lib/python3.10/site-packages/openai/_base_client.py:957\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    955\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm_api/lib/python3.10/site-packages/openai/_base_client.py:993\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    990\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 993\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    999\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm_api/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm_api/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm_api/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm_api/lib/python3.10/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm_api/lib/python3.10/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm_api/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm_api/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm_api/lib/python3.10/site-packages/httpcore/_sync/http_proxy.py:344\u001b[0m, in \u001b[0;36mTunnelHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;241m=\u001b[39m HTTP11Connection(\n\u001b[1;32m    338\u001b[0m                 origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remote_origin,\n\u001b[1;32m    339\u001b[0m                 stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    340\u001b[0m                 keepalive_expiry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keepalive_expiry,\n\u001b[1;32m    341\u001b[0m             )\n\u001b[1;32m    343\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm_api/lib/python3.10/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm_api/lib/python3.10/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm_api/lib/python3.10/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm_api/lib/python3.10/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm_api/lib/python3.10/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm_api/lib/python3.10/ssl.py:1292\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1290\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1291\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/llm_api/lib/python3.10/ssl.py:1165\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load input data\n",
    "    with open(question_data_path, 'r', encoding='utf-8') as file:\n",
    "        q_json_list = json.load(file)\n",
    "\n",
    "    # Users can specify a range to process the corresponding subset of data\n",
    "    # For example, from index 0 to 100 (excluding 100), processing the first 100 JSON entries\n",
    "    start_idx = 0\n",
    "    end_idx = 1  # Specify processing data in the range 0-101\n",
    "\n",
    "    results = main_answer(q_json_list, start_index=start_idx, end_index=end_idx)\n",
    "\n",
    "    # Write the processing results to a file\n",
    "    with open('result-2.json', 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(results, json_file, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
